{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/BubbleQuick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ee2e92",
      "metadata": {
        "id": "a6ee2e92"
      },
      "source": [
        "# CSV Handling with Pandas\n",
        "\n",
        "We have already started to learn about how `matplotlib` can be used to create excellent charts and graphs, but that was using datasets that were small enough to be typed directly into the notebook.\n",
        "\n",
        "`pandas` is an elegant and efficient python module for slurping in arbitrarily large data files, and handling them by column *name* rather than by index *number* (i.e. pandas enables ***Literate Programming***)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033b3d1b",
      "metadata": {
        "id": "033b3d1b"
      },
      "outputs": [],
      "source": [
        "# As usual, the first step is to import the required python libraries\n",
        "import numpy             as np    # all kinds of numerical and matrix capabilities in here\n",
        "import matplotlib.pyplot as plt   # this is for making charts and graphs\n",
        "import pandas            as pd    # for convenient handling of csv files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3defbb83",
      "metadata": {
        "id": "3defbb83"
      },
      "source": [
        "## DataFrames\n",
        "The top-level datatype in pandas is a `DataFrame`. Think of it as one spreadsheet tab from Google Sheets or Microsoft Excel.\n",
        "\n",
        "When you ask `pandas` to read a data file, it returns a `DataFrame` object, so it is conventional to use a variable that has `df` in the name.\n",
        "\n",
        "As usual in a python notebook, if we just mention a variable at the end of a cell, the notebook tries to show it to us. A `DataFrame` can be quite big, so usually it shows just a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71a78ea",
      "metadata": {
        "id": "a71a78ea"
      },
      "outputs": [],
      "source": [
        "# csv = comma-separated-value is the most common/simple type of data file\n",
        "# pandas can even reach out to URLs on the internet to slurp in data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/RubeRad/tcscs/master/BubbleQuick.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcefb3a",
      "metadata": {
        "id": "efcefb3a"
      },
      "source": [
        "### DataFrames as Objects\n",
        "I said above a `DataFrame` is an *object*. What it means to be an *object* in programming is to not just be a singular piece of data, but to have:\n",
        "* *attributes* or *elements* -- an object is an organized collection of not just one, but many data elements\n",
        "* *methods* or *functions* -- an object knows how to do certain things that are relevant to its nature\n",
        "\n",
        "A simpler way to think of it, an object is a bag of nouns and verbs.\n",
        "\n",
        "And like Plato's idealized concept of chair, an object itself is abstract. Every *instance* (concrete) of an object type has specific values of its attributes, and behaviors of its methods.\n",
        "\n",
        "For instance, if there were a software object called `Dog`, some of its attributes might be `color`,  or `breed`, and some of its functions might be `speak()`, or `is_hungry()`. A variable `fluffy` that is a Dog object might have attribute values of `color='white'`, `breed='toy pomeranian'`, and its `speak()` method might return `yip`. A  variable `spike` that is also a Dog object might have attribute values of `color='black'`, `breed='doberman pinscher'`, and its `speak()` method might return `GRRR!`.   (For all dogs, the `is_hungry()` method probably always returns `True`.)\n",
        "\n",
        "In python, you access/reference an attribute of a variable with a certain object type, by stating the name of the variable, then a `.`, then the name of the attribute. Here are a couple of the most interesting *attributes* of every `DataFrame` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22619b1d",
      "metadata": {
        "id": "22619b1d"
      },
      "outputs": [],
      "source": [
        "df.shape    # (rows, columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb351db",
      "metadata": {
        "id": "3bb351db"
      },
      "outputs": [],
      "source": [
        "df.columns  # list of names of columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f222b2",
      "metadata": {
        "id": "f6f222b2"
      },
      "source": [
        "Methods are not *accessed* or *referenced* as data that merely *is* something, but *invoked*, since they are functions that *do* something. Methods are invoked similarly to referencing attributes, but always with (). Methods can also accept input parameters inside the (), just like the \"`bare functions`\" we have already seen how to make in python with `def`.\n",
        "\n",
        "Here are a few of methods of the DataFrame object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f723f16",
      "metadata": {
        "id": "6f723f16"
      },
      "outputs": [],
      "source": [
        "df.describe()    # a statistical description of the contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78dce3f3",
      "metadata": {
        "id": "78dce3f3"
      },
      "outputs": [],
      "source": [
        "df.info()        # a more computer-science kind of description centered on data types and storage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1349fe",
      "metadata": {
        "id": "4f1349fe"
      },
      "source": [
        "Compare these three ways to print a selection of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b8394e",
      "metadata": {
        "scrolled": true,
        "id": "e8b8394e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05686c19",
      "metadata": {
        "id": "05686c19"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de6549b",
      "metadata": {
        "id": "9de6549b"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31656d25",
      "metadata": {
        "id": "31656d25"
      },
      "source": [
        "As you can see, `head()` and `tail()` default to showing the first/last 5 rows (you can put a different number into the () -- try it!); and just mentioning the `DataFrame` variable does a `head()` and a `tail()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c09fa1",
      "metadata": {
        "id": "91c09fa1"
      },
      "source": [
        "## DataFrame columns\n",
        "As we saw above, pandas is aware of the columns of the dataset, by their *names* (the string labels in the top row of the .csv file). You can refer to any particular column using square brackets, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166d23f2",
      "metadata": {
        "id": "166d23f2"
      },
      "outputs": [],
      "source": [
        "df['ALGORITHM']  # try all the available column names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f3190e3",
      "metadata": {
        "id": "7f3190e3"
      },
      "source": [
        "A `DataFrame` column is also an object (technically the name of the object is `Series`, but since you find the names of the `Series` with the `DataFrame` attribute `columns`, we'll just call them columns). As an object, a column also has some useful methods. `describe()`, invoked on a column, behaves analogously to being invoked on a whole `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4adb52a0",
      "metadata": {
        "id": "4adb52a0"
      },
      "outputs": [],
      "source": [
        "df['ALGORITHM'].describe()  # try all the column names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d55986",
      "metadata": {
        "id": "75d55986"
      },
      "source": [
        "Another very useful method available for column objects is `value_counts()` -- what is that explaining about the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff3917ec",
      "metadata": {
        "id": "ff3917ec"
      },
      "outputs": [],
      "source": [
        "df['ALGORITHM'].value_counts() # try all the column names. When is value_counts() more/less useful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bafabe4",
      "metadata": {
        "id": "3bafabe4"
      },
      "source": [
        "## DataFrame column combination\n",
        "One of the elementary uses for a spreadsheet is to populating a new column using cell formulas to combine columns that already exist. Analogously, pandas makes it very easy to create new columns from previous.\n",
        "\n",
        "Derived columns will appear in the list of columns like the ones read from the raw data, and have all the same methods available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7aa90e",
      "metadata": {
        "id": "6c7aa90e"
      },
      "outputs": [],
      "source": [
        "# OPS is the column we really care most about!\n",
        "df['OPS'] = df['COMPS'] + df['SWAPS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ef8a5e",
      "metadata": {
        "id": "e0ef8a5e"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39fa6077",
      "metadata": {
        "id": "39fa6077"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b713bb90",
      "metadata": {
        "id": "b713bb90"
      },
      "outputs": [],
      "source": [
        "df['OPS'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6c3b0c",
      "metadata": {
        "id": "2c6c3b0c"
      },
      "outputs": [],
      "source": [
        "df['OPS'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e912fb",
      "metadata": {
        "id": "b7e912fb"
      },
      "source": [
        "## DataFrame rows and slicing\n",
        "Perhaps the most powerful and flexible aspect of pandas is the ability to *slice* the data, allowing you to select any subset of the data you want to deal with.\n",
        "\n",
        "Recall that `==` is asking a *question*. Before executing this next cell, consider, what would expect to be the answer to the question?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3293b18e",
      "metadata": {
        "id": "3293b18e"
      },
      "outputs": [],
      "source": [
        "df['ALGORITHM'] == 'BUBBLE' # == is always a question. \n",
        "# What is it asking?\n",
        "# What does the answer mean?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5acd00d6",
      "metadata": {
        "id": "5acd00d6"
      },
      "source": [
        "What is the size of that thing which is the answer to the question? What does it mean?\n",
        "\n",
        "We can catch the answer to the question in a variable. And then we can give that variable to the `DataFrame` object.\n",
        "\n",
        "Pandas is clever enough to understand that, when we use square brackets to give it a single string, we want that column. But if we give it a list of booleans that is the same length as the number of rows of data, it will line up the Trues/Falses with the rows, and give us back just the rows that are True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b000668d",
      "metadata": {
        "id": "b000668d"
      },
      "outputs": [],
      "source": [
        "# We can catch the answer to the question in a variable\n",
        "bubblerows = df['ALGORITHM']=='BUBBLE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2117c11",
      "metadata": {
        "id": "e2117c11"
      },
      "outputs": [],
      "source": [
        "df[bubblerows]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e087fb31",
      "metadata": {
        "id": "e087fb31"
      },
      "source": [
        "When pandas gives us back the selected rows (the requested 'slice' of the data), it gives us back another `DataFrame` object, and we can hold that sliced `DataFrame` in another variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb5ff8d0",
      "metadata": {
        "id": "bb5ff8d0"
      },
      "outputs": [],
      "source": [
        "df_bubble = df[bubblerows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8653ec5b",
      "metadata": {
        "id": "8653ec5b"
      },
      "outputs": [],
      "source": [
        "# Use this cell to examine the sliced DataFrame df_bubble\n",
        "# in all the ways we learned about up top with the full DataFrame df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ea953c",
      "metadata": {
        "id": "d4ea953c"
      },
      "source": [
        "This slicing operation can also be done in a single python statement, like below. This is very common pattern, examine it closely and expect to do it a lot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc23b229",
      "metadata": {
        "id": "bc23b229"
      },
      "outputs": [],
      "source": [
        "# notice this:   vvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
        "df_bubble = df[  df['ALGORITHM'] == 'BUBBLE'  ]\n",
        "# is the same as what we saved off into variable \"bubblerows\"\n",
        "# This time, we just wrap that with df[]\n",
        "# We get to skip a step, and one less variable hanging around\n",
        "# (and one less variable we need to think of a Literate Programming name for)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805da88d",
      "metadata": {
        "id": "805da88d"
      },
      "outputs": [],
      "source": [
        "# In this cell, create a DataFrame slice df_quick to go with df_bubble\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e8d122",
      "metadata": {
        "id": "75e8d122"
      },
      "source": [
        "Since `df_bubble` and `df_quick` are also `DataFrame` objects, they can also create new columns by combining other columns.\n",
        "\n",
        "Recall that, for Bubble Sort, the expected number of total operations is `1.5*COMPS` (why?). So let's make a column `EXP` so we can compare it to the actual number of operations in column `OPS`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe11aa3",
      "metadata": {
        "id": "bbe11aa3"
      },
      "outputs": [],
      "source": [
        "df_bubble['EXP'] = df_bubble['COMPS'] * 1.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e21eb7a6",
      "metadata": {
        "id": "e21eb7a6"
      },
      "source": [
        "Oopx! What happened there?\n",
        "\n",
        "A slice is not (normally) a separate copy of the data. To avoid wasting memory, when pandas gives a slice `DataFrame`, it is like a lens or a prism, that sees just the right part of the original data.\n",
        "\n",
        "When we try to create a new column in the *slice*, pandas says \"Wait a minute, how am I supposed to deal with this back in the original full `DataFrame`? If there's a new column EXP for everybody, what am I supposed to do for EXP on all the rows that are not in this slice?\n",
        "\n",
        "There are multiple ways to deal with this, but for now we'll take the easy road and just go ahead and be wasteful of memory. \n",
        "\n",
        "Go back up to the two cells that create the `df_bubble` and `df_quick` slices, and add a `.copy()` on the end.\n",
        "\n",
        "After `df_bubble` has its EXP column defined, use the next cell to calculate EXP appropriately for `df_quick`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "459459bf",
      "metadata": {
        "id": "459459bf"
      },
      "outputs": [],
      "source": [
        "# What is the EXPected number of QuickSort operations for N cards?\n",
        "# Hint: numpy offers a log-base-2 function called np.log2()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf34e07",
      "metadata": {
        "id": "caf34e07"
      },
      "source": [
        "## Pandas and Matplotlib -- a match made in heaven!\n",
        "Here's the main point. `pandas` columns can be handed over to `matplotlib` to be either the x's or y's for data series to `plot()`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "005b2fb7",
      "metadata": {
        "id": "005b2fb7"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "ax = plt.gca()\n",
        "ax.plot(df_bubble['N'], df_bubble['OPS'])\n",
        "ax.plot(df_quick['N'],  df_quick['OPS'])\n",
        "# plot both 'EXP' series as well!\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0268627e",
      "metadata": {
        "id": "0268627e"
      },
      "source": [
        "# Homework\n",
        "\n",
        "## Exercise I: Matplotlib styling review\n",
        "Finish the ugly graph above:\n",
        "* Add the EXPected series\n",
        "* Rock the matplotlib styling to make it an excellent graph\n",
        "  * (Feel free to refer back to the MatplotlibIntro notebook)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef42581",
      "metadata": {
        "id": "bef42581"
      },
      "source": [
        "## Exercise II: Practice with slicing and plotting\n",
        "\n",
        "\n",
        "In code cells below, do the following:\n",
        "1. Make a slice of all the quicksort rows with N between 15 and 25; make a plot of x=N,y=OPS from the slice.\n",
        "1. Make a slice of `df` (the original full `DataFrame`) of rows with OPS between 100 and 200. Make a plot of N,OPS from the slice.\n",
        "1. Make a new column in the original `df` called `SWAPS_PER_COMP` (SWAPS divided by COMPS). Create two slices that re-slice `df` by ALGORITHM==BUBBLE/QUICK as before (unfortunately, new columns added to the original `DataFrame` do not magically show up in `df_bubble` and `df_quick`). Make a plot x=N and two data series, SWAPS_PER_COMP for bubblesort vs quicksort.\n",
        "1. Make a slice from `df_bubble` for which OPS is less than EXP, and another slice for which OPS is more than EXP. Make a plot that shows the EXPected line from `df_bubble`, with the OPS actual values from the less/more slices scattered above and below with different colors.\n",
        "\n",
        "Notes:\n",
        "1. Above, we sliced `df` using `==` on the text-valued column `ALGORITHM`. In these exercises you will be slicing based on columns with numerical data, using comparators like `<` or `>=`. You will also need to use the logical operator `and`.\n",
        "1. For each of these, you should think of a concise but not confusing variable name for the slice\n",
        "1. None of these plots need to be pretty, just make sure they are scatter or line as appropriate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dc1611",
      "metadata": {
        "id": "43dc1611"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}