{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "batYvyKogmjr",
        "0akQA539gx6A",
        "_a-VjCaxjYS8",
        "gUSLh6YEhAV0",
        "JMo2g6cgh8sq",
        "oGkYiX-DnHUa"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/Mq25zlems8rZrV+d87Sb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/GPT2_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set up the notebook to do GPT stuff\n",
        "\n",
        "This will be necessary every restart\n",
        "\n",
        "Make sure you are using a GPU! Runtime/"
      ],
      "metadata": {
        "id": "batYvyKogmjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you are using a GPU! This cell should say so. If not, Runtime/Change Runtime Type, and choose \"T4 GPU\""
      ],
      "metadata": {
        "id": "qfig194Iql_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Ecpn52VKgdR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and install the publicly-available GPT-2 module so we can import it"
      ],
      "metadata": {
        "id": "zkYXESVaq5B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt-2-simple"
      ],
      "metadata": {
        "id": "9FcmOhOllrTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the necessary python imports"
      ],
      "metadata": {
        "id": "84p2wbJxrDaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqS_rFtMlZUS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import gpt_2_simple as gpt2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "which='124M' # or '355M' or '774M' or '1558M'\n",
        "# NOTE: 774/1558 can only be run vanilla;\n",
        "# Colab is not powerful enough to retrain them"
      ],
      "metadata": {
        "id": "_Kn6X0YNgJFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download the files for the pretrained GPT-2 model\n",
        "\n",
        "This may not be necessary; if you just restarted the runtime, you're using the same virtual machine, and the files will still be there."
      ],
      "metadata": {
        "id": "0akQA539gx6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2(model_name=which)"
      ],
      "metadata": {
        "id": "_LIlpQANlpbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Initiate a Session\n",
        "\n",
        "This will be necessary every restart\n",
        "\n"
      ],
      "metadata": {
        "id": "_a-VjCaxjYS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate a 'session'\n",
        "# To get a new session, Runtime/Restart\n",
        "sess = gpt2.start_tf_sess()"
      ],
      "metadata": {
        "id": "qWrFnuS5bv9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Play with vanilla GPT-2\n",
        "\n",
        "Use the session to play with GPT-2 as trained/released by OpenAI"
      ],
      "metadata": {
        "id": "gUSLh6YEhAV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained GPT2 files that were previously\n",
        "# downloaded and saved onto this VM\n",
        "gpt2.load_gpt2(sess, model_name=which)"
      ],
      "metadata": {
        "id": "-iteaIcZhJVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some text\n",
        "gpt2.generate(sess, model_name=which,            # don't mess with these\n",
        "              prefix='The most important thing', # DO mess with these!\n",
        "              length=100)"
      ],
      "metadata": {
        "id": "wQCIsK-8bv64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other optional-but-helpful parameters for gpt2.generate and friends:\n",
        "\n",
        "* **length**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **temperature**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **top_k**: Limits the generated guesses to the top k guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set top_k=40)\n",
        "* **top_p**: Nucleus sampling: limits the generated guesses to a cumulative\n",
        "* **probability**. (gets good results on a dataset with top_p=0.9)"
      ],
      "metadata": {
        "id": "OgcXSNnehg4T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xt2eowqIbvwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Train GPT to talk like Shakespeare!\n",
        "\n",
        "First: Runtime/Restart session\n",
        "\n",
        "Then: rerun sections 1 (setup) and 3 (new session)\n"
      ],
      "metadata": {
        "id": "JMo2g6cgh8sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname = \"shakespeare.txt\"\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "data = requests.get(url)\n",
        "with open(fname, 'w') as f:\n",
        "\tf.write(data.text)"
      ],
      "metadata": {
        "id": "8cJxs3nNmISm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.finetune(sess,\n",
        "              fname,\n",
        "              run_name='shakey',\n",
        "              steps=100,\n",
        "              print_every=5,\n",
        "              sample_every=25,\n",
        "              sample_length=100)"
      ],
      "metadata": {
        "id": "cVRIOTKamv4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, model_name=which,\n",
        "              prefix='LORD')"
      ],
      "metadata": {
        "id": "K95Qza0ym7dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train GPT-2 to mimic other literature\n",
        "\n",
        "* King James Bible?\n",
        "* The Sound and the Fury?\n",
        "* Moby Dick?\n",
        "* Mark Twain?\n",
        "\n",
        "First: Runtime/Restart session\n",
        "\n",
        "Then: rerun sections 1 (setup) and 3 (new session)\n",
        "\n",
        "Then: upload training text\n",
        "\n"
      ],
      "metadata": {
        "id": "oGkYiX-DnHUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname =    # what's the name of your uploaded file?"
      ],
      "metadata": {
        "id": "8vHiJoRmntH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.finetune(sess,\n",
        "              fname,\n",
        "              run_name= ,  # name your run\n",
        "              steps=100,\n",
        "              print_every=5,\n",
        "              sample_every=25,\n",
        "              sample_length=100)"
      ],
      "metadata": {
        "id": "z5Yjj7cjoIAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, model_name=which,\n",
        "              prefix=)  # what's a good prefix?"
      ],
      "metadata": {
        "id": "JiIyX9L1o4Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tzObWiQXpq1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}