{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh7tVQ31JKB0"
   },
   "source": [
    "# Python Notebook for MNIST neural network\n",
    "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
    "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
    "  - For Markdown cells, 'execute' means render the formatting.\n",
    "  - For Code cells, 'execute' means run the python.\n",
    "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
    "1. Any cell can be edited (double-click into it) and re-executed (SHIFT-ENTER again).\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gH-qirsnJKB3"
   },
   "source": [
    "# Setup\n",
    "This first code cell includes import statements, which set up libraries of ready-to-go capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vql1fPZIJKB4"
   },
   "outputs": [],
   "source": [
    "import random                      # so we can display random images from the dataset\n",
    "import numpy as np                 # numpy is everything with arrays and matrices, 'np' is a commonly-used nickname\n",
    "import matplotlib.pyplot as plt    # most common python graphing library\n",
    "import tensorflow as tf            # tensorflow is a deep learning framework.\n",
    "from   tensorflow   import keras   # tensorflow.keras offers higher-level control of common tensorflow tasks\n",
    "from   sklearn      import metrics # we get the 'confusion_matrix' function from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE53lxVuJKB5"
   },
   "source": [
    "The tensorflow keras library includes some datasets for training. The Modified National Institute of Standards and Technology (MNIST) dataset is 70000 images of handwritten numerical digits; each a 28x28 pixel image, and corresponding labels specifying the right answer for each.\n",
    "\n",
    "The dataset is pre-divided into 60000 images for training the neural network, and 10000 held back from the training set for independent testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ds_mMV9JKB6"
   },
   "outputs": [],
   "source": [
    "# Fetch the dataset, pre-divided into train/test, and labels for each\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold off and don't execute this immediately; use the cells below to investigate the data, and then come back and run this and peek at them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a little data prep here, we scale the pixel values from the range 0..255 to 0..1.0 \n",
    "# (numpy makes it simple, every value in every 28x28 array gets scaled by the one divisor).\n",
    "train_images = train_images / 255.0  # rescale from 0..255 to 0..1.0\n",
    "test_images  = test_images  / 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the data looks to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we just get? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = len(train_images)\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyhEZ_ImJKB8"
   },
   "source": [
    "## Exercise\n",
    "Can you tell from the layout of the nonzero numbers what digit that is? Try looking at `train_images[3]` or `test_images[2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = len(test_images)\n",
    "ntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ayk6ly1AJKB8"
   },
   "source": [
    "## How the data looks to humans\n",
    "Let's take a look at what some of these handwritten digits look like when displayed as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd2yFD-wJKB9"
   },
   "outputs": [],
   "source": [
    "which = 0\n",
    "#which = random.randint(0, ntrain-1)\n",
    "image = train_images[which]\n",
    "#ansa  = train_labels[which]\n",
    "\n",
    "# Matplotlib can, instead of plot(), imshow() \n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.imshow(image)  # , cmap=plt.cm.binary)\n",
    "\n",
    "#ax.set_xticks( [] )\n",
    "#ax.set_yticks( [] )\n",
    "#caption = 'train_images[{}] is a {}'.format(which, ansa)\n",
    "#ax.set_xlabel(caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzG0NIdlJKB9"
   },
   "source": [
    "## Exercise \n",
    "* In the graphing cell above, uncomment the extra parts one by one, see what happens.\n",
    "* Change it to show an image from the test set instead of the training set\n",
    "* Go back to the cell which divides the train/test image pixel values by 255, and rerun up to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLEgNAtJJmgU"
   },
   "source": [
    "## Functions for plotting training and test cases\n",
    "Here's a function for drawing an image and a caption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qejKhx28JKB-"
   },
   "outputs": [],
   "source": [
    "def plot_image(ax,   # a matplotlib Axes to draw the image onto\n",
    "               img,  # the image to draw\n",
    "               cap): # caption text\n",
    "    \n",
    "    # Draw the image with the colormap that draws 0=white-->1=black\n",
    "    ax.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    # get rid of the pixel row/column counters\n",
    "    ax.set_xticks( [] )\n",
    "    ax.set_yticks( [] )\n",
    "\n",
    "    # use that caption as the label for the X axis\n",
    "    ax.set_xlabel(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka6JklYmJyH-"
   },
   "source": [
    "Now that the function is written, test it out and make sure it works (and you understand how it works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sedTkHkJKB-"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot() \n",
    "img = train_images[0]\n",
    "ansa = train_labels[0]\n",
    "cap = 'train[{}] is a {}'.format(0, ansa)\n",
    "plot_image(ax, img, cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* Change the cell above to plot the first *test* image instead of the first *training* image\n",
    "  * (And appropriate caption)\n",
    "* Change the cell above to plot *both* the first training and testing images\n",
    "  * (Refer to the Matplotlib intro/Anscombe's quartet for a reminder of how to use multiple subplots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RjlHndoJ4t2"
   },
   "source": [
    "It's still a lot of typing or pasting to get it to render a particular training or test image. Here's a function to render a training image, given just a number.\n",
    "\n",
    "Test it, and then make the analogous function for test images (and test it).\n",
    "\n",
    "We will use these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knDuRTsmJKB_"
   },
   "outputs": [],
   "source": [
    "# Here's a function to plot and caption a training image\n",
    "def plot_training_image(idx):\n",
    "    fig = plt.figure()   # boilerplate stuff\n",
    "    ax  = fig.add_subplot()\n",
    "    img = train_images[idx]   # this is the training image we want to plot\n",
    "    ansa = train_labels[idx]  # this is the correct answer for what it is\n",
    "    cap = 'train[{}] is a {}'.format(idx, ansa)  # build a caption string\n",
    "    plot_image(ax, img, cap)  # plot & caption on this ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78zm-Z3DJKB_"
   },
   "outputs": [],
   "source": [
    "plot_training_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy7DVmdGJKB_"
   },
   "outputs": [],
   "source": [
    "# Use this cell to make a function to plot and caption a test image\n",
    "def plot_test_image(idx):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--Mjsp79JKCA"
   },
   "outputs": [],
   "source": [
    "# Now test it\n",
    "plot_test_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SPGLSv5JKCA"
   },
   "source": [
    "This python code renders 25 `train_images` in a 5x5 grid. In the middle of the loop you can switch between `which=i` and `which=random...` to control which 25 get displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRWmIFNYJKCA"
   },
   "outputs": [],
   "source": [
    "# This cell shows 5x5 training images (first 25 or random 25)\n",
    "fig = plt.figure(figsize=(10,10))  # 10x10 'inches'\n",
    "\n",
    "for i in range(25): # i = 0...24\n",
    "    # set up each next subplot\n",
    "    ax = fig.add_subplot(5,5, i+1)       # in a 5x5 grid, setup subplot 1...25\n",
    "    \n",
    "    # which training image to show?\n",
    "    which = i                            # show the ith training image\n",
    "    #which = random.randint(0,ntrain-1)  # show a random image\n",
    "    \n",
    "    # fill these out\n",
    "    img = ...\n",
    "    ansa = ...\n",
    "    cap = ...\n",
    "    plot_image(ax, img, cap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aizw95I9JKCB"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "* Fill in the `img=`, `ansa=`, `cap` lines so the `plot_image()` command has what it needs to run\n",
    "* Refactor so the `plot_image()` call is just one longer line\n",
    "* Uncomment the `which = random` line, and re-run to generate a bunch more grids of digit images. Can you find some that look ambiguous and might be difficult?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUC_K2K9JKCB"
   },
   "source": [
    "# Neural Network Analysis\n",
    "## Structure the Network\n",
    "This is where we set up the structure of the neural network, and run the training. The model has 3 layers:\n",
    "\n",
    "1. The first/input `Flatten` layer maps the individual pixel values from their 28x28 grid to an array of 784 values.\n",
    "1. The second/middle layer is `Dense`, which means an arc from each of the 784 first-layer nodes, to each of the 2nd-layer nodes.   \n",
    "  * `relu` (\"rectified linear unit\") is the most common 'activation function', and all it does is check whether the sum of scaled/biased inputs is positive or not. \n",
    "  * If it is positive, it 'fires' by outputting that value. \n",
    "  * If it is negative, it doesn't fire (or rather, outputs the value 0).\n",
    "1. The third/output layer (also `Dense`) must have 10 nodes, because we are classifying the 10 different digits. \n",
    "  * `softmax` takes the 10 numerical values that accumulate in the 10 nodes, and rescales them so they are positive and sum to 1. \n",
    "  * This way we can interpret them as probabilities (of being various digits)\n",
    "\n",
    "Note for the middle layer we can choose more or fewer nodes, but the outer layers have to fit the input and output. Also we could add more intermediate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gzkm4Q9vJKCB"
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   # input  layer; one node per pixel\n",
    "    keras.layers.Dense(16, activation='relu'),    # middle layer; may be changed to more nodes\n",
    "    keras.layers.Dense(10, activation='softmax')  # output layer; must have 10 nodes because 10 digits\n",
    "])\n",
    "\n",
    "# 'compile' basically means get ready to run\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62p9I5WLJKCC"
   },
   "source": [
    "## Train the Network\n",
    "This is where the computation happens:\n",
    "- Forward-propagation from pixel inputs through the network, to scores in the output layer\n",
    "- Comparison of scores to truth, yielding errors\n",
    "- Back-propagation from errors to update coefficients in the network\n",
    "\n",
    "The two output statistics are\n",
    "* **accuracy** the percentage of the 60000 training images predicted correctly. \n",
    "* **loss**: a penalty for not assigning probability 1 to the correct answer; see below\n",
    "\n",
    "The number of training epochs can be increased until convergence (the model stops improving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tfih1X17JKCC"
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmLqh25KJKCC"
   },
   "source": [
    "Now that the model has been trained, it's got weights -- scale factors for the edges, and biases for the nodes. Look at all the shapes of the parts of `model.weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbXLRIK2JKCD"
   },
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RQm5__tJKCD"
   },
   "source": [
    "## Evaluate the Network\n",
    "Now that the model is trained (the network coefficients have been fit to the training data), we test it by evaluating on the test images it has never seen.\n",
    "\n",
    "Note that **accuracy** and **loss** are also computed to evaluate the performance of the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Br5OWobWJKCD"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mj_PbrESJKCD"
   },
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJR1lCN2JKCD"
   },
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_3AN9kZJKCE"
   },
   "source": [
    "How do those values of loss and accuracy on the *test* set, compare to loss and accuracy from the *training*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd3AibpuJKCE"
   },
   "source": [
    "## Look at the predictions\n",
    "The point of the network is to predict what digit an image is. We can run the model on all the `test_images` and get all the predictions, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhNwT-FCJKCE"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIjK44OeJKCE"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine a particular test image and its prediction from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu0RyqyRJKCF"
   },
   "outputs": [],
   "source": [
    "which = 0                            # first we'll look at test case 0\n",
    "#which = random.randint(0, ntest-1)   # later we can do random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1G6PYmSJKCF"
   },
   "outputs": [],
   "source": [
    "preds = predictions[which]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXaa5OUcJKCF"
   },
   "source": [
    "What is `predictions[0]`? How big is it? (Why is it that big?) What is it saying? Is this prediction correct?\n",
    "\n",
    "`predictions[0]` is supposed to predict the right answer for test case number 0. What is the right answer for test case number 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GW18zQGWJKCF"
   },
   "outputs": [],
   "source": [
    "ansa = test_labels[which]\n",
    "ansa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLexjgDuJKCF"
   },
   "source": [
    "`predictions[0]` is the neural network output layer, when `test_images[0]` is fed into the input layer of the network. What is `test_images[0]` anyways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaDIbUFRJKCG"
   },
   "outputs": [],
   "source": [
    "# use this cell to get matplotlib to show a picture of test_images[0]\n",
    "plot_test_image(which)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCe6X5MJJKCG"
   },
   "outputs": [],
   "source": [
    "max(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_IeBqpfJKCG"
   },
   "outputs": [],
   "source": [
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAHzAMisJKCG"
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSwtZnk-JKCG"
   },
   "outputs": [],
   "source": [
    "# two kinds of printouts\n",
    "if pred == ansa:              # if the model predicted the right ansa        \n",
    "    p = 100 * preds[ansa]\n",
    "    print('The highest-probability prediction is {:.1f}% for {}, which is correct'.format(p,ansa))\n",
    "else:\n",
    "    q = preds[ansa]     # this is what we SHOULD have chosen\n",
    "    p = preds[pred]     # but this larger probability is what DID get chosen\n",
    "    print('The correct answer {} had probability {:.1f}%'.format(ansa, 100*q))\n",
    "    print('But the prediction {} had probability {:.1f}%'.format(pred, 100*p))\n",
    "    # compute and print 'loss' here, see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_E5Q301JKCH"
   },
   "outputs": [],
   "source": [
    "# Plot the 10 predictions as a bar graph\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "#ax.set_xticks(range(10)) # xticks at 0,1,...9, matching the digit labels\n",
    "\n",
    "barplot = ax.bar(range(10), preds, color=\"gray\")\n",
    "\n",
    "# remember 'pred' and 'ansa' that were set a few cells above?\n",
    "#barplot[pred].set_color('red')\n",
    "#barplot[ansa].set_color('blue')\n",
    "# why does this work? what happens if pred==ansa vs if pred!=ansa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcB8oJD6JKCH"
   },
   "source": [
    "## Understand 'loss'\n",
    "If everything is working right, preds has a probability of 1 for the correct answer (and the bar graph has a near-1-height bar) . If the prediction probability for the right answer is less than 1, that is the basis for computing 'loss', as in the next cell. \n",
    "\n",
    "The reported 'loss' (along with accuracy) is the average of these values for all cases (across either the test set or training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eX8UcpQqJKCH"
   },
   "outputs": [],
   "source": [
    "q = preds[ansa]  # remember ansa is the truth label (and the index of the truth label)\n",
    "q                # for a good prediction, this should be near 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPnGN3A8JKCH"
   },
   "outputs": [],
   "source": [
    "# This is the formula for loss\n",
    "loss = np.log2(1.0/q)    # If q is almost 1, this is almost 0. \n",
    "                         # The smaller q gets, the bigger 1/q gets, so the larger log(1/q) gets\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2FpatBvJKCH"
   },
   "source": [
    "# Exercise\n",
    "* Add a loss calculation and printout to the `if/else` cell above\n",
    "* Repeat the cells above, setting `which` to different indices, or letting it be random. Can you find any interesting cases which are wrongly-predicted, or more marginal than an easy correct prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqX4n3ZJJKCI"
   },
   "source": [
    "## Confusion Matrix\n",
    "Here is the list of all the correct answers (most not printed, because 10,000 is too long!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSsu8I5ZJKCI"
   },
   "outputs": [],
   "source": [
    "test_labels # these are the correct answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiKWao71JKCI"
   },
   "source": [
    "As we saw above, each prediction is an array of 10 floating point numbers. This cell applies `argmax` to each to get the index of the largest score in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eir_9h6rJKCI"
   },
   "outputs": [],
   "source": [
    "test_preds = predictions.argmax(axis=1) # these are the predictions; the index of the largest score for each test\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W0RUlFSJKCI"
   },
   "source": [
    "As you can see, first three predictions and the last three predictions match the truth. But since accuracy was not 100%, there are some mismatches in those 9994 that are not printed. \n",
    "\n",
    "The 'confusion matrix' generated by the next cell details which numbers were mistaken for which. The rows of the matrix mean 'which digit it actually is'. The columns mean 'which digit was predicted'. \n",
    "\n",
    "What is the meaning of the large diagonal values? Other than the upper-left value, what's the largest value in the first column? What does it mean? What's the largest off-diagonal value, and what does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g55Ee37WJKCI"
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W39ZQX4-JKCJ"
   },
   "source": [
    "## Visualize groups of results\n",
    "Below is more complex code that graphs a large number of test results, with the bar graph red to highlight wrong answers.\n",
    "\n",
    "The cells with `def` create functions (python analogues of Snap! custom blocks), and only have to be run once. The last block can be rerun many times, especially if `which` is set to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yz6_R-E5JKCJ"
   },
   "outputs": [],
   "source": [
    "# This function plots predictions (an array of 10 scores) as a bar graph,\n",
    "# color coding blue for true, red for error\n",
    "def plot_predictions(ax, i, predictions, true_label):\n",
    "  ax.grid(False)\n",
    "  ax.set_xticks(range(10))\n",
    "  #ax.set_yticks([])  # let there be yticks, so we can see the scale of the barplot\n",
    "  barplot = ax.bar(range(10), predictions, color=\"#777777\")\n",
    "  ax.set_ylim([0, 1])\n",
    "  pred_label = np.argmax(predictions)\n",
    "\n",
    "  barplot[pred_label].set_color('red')   # set the prediction red\n",
    "  barplot[true_label].set_color('blue')  # set the truth blue\n",
    "  # if the prediction was right, it will just be blue\n",
    "  # if the prediction was wrong, the truth will be blue, \n",
    "  # and the incorrect prediction still red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuFrpnkiJKCJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# This uses the functions above to graph images and bar graphs in a grid.\n",
    "# In the middle again choose either which=i for the first results, or which=random\n",
    "\n",
    "# 6 rows, and 4 columns\n",
    "num_images = 6*4\n",
    "# BUT, next to each image we also plot its prediction bar graph\n",
    "# so really 8 columns\n",
    "\n",
    "subplot_i = 0 # we will actually start with 1\n",
    "\n",
    "for i in range(num_images):\n",
    "    which = i # as before, leave this for sequential, or uncomment the next line for random\n",
    "    #which = random.randint(0, len(test_images)-1)\n",
    "    \n",
    "    img   = test_images[which] # this is the image we're trying to predict\n",
    "    ansa  = test_labels[which] # this is the correct answer\n",
    "    \n",
    "    preds = predictions[which] # the 10 scores from the output layer\n",
    "    score = np.max(preds)      # max score\n",
    "    pred  = np.argmax(preds)   # index of max score (i.e. prediction)\n",
    "    pct   = round(score*100)\n",
    "    cap   = '#{}({}) {}%'.format(which, ansa, pct)\n",
    "    \n",
    "    subplot_i = subplot_i + 1                # advance to the next subplot number\n",
    "    imgax = fig.add_subplot(6,8, subplot_i)  # create the new subplot\n",
    "    plot_image(imgax, img, cap)\n",
    "    \n",
    "    subplot_i = subplot_i + 1                # advance to the next subplot number\n",
    "    barax = fig.add_subplot(6,8, subplot_i)  # create the new subplot\n",
    "    plot_predictions(barax, which, preds, ansa)    \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hnt4gEZDJKCJ"
   },
   "source": [
    "# Homework\n",
    "(See also Schoology)\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "* Make sure the network is structured with the middle Dense layer set to 16 nodes, and epochs to 1 (so that incorrect predictions are relatively common).\n",
    "* Just in case, re-execute the Structure/Train/Evaluate cells to (badly) retrain the network\n",
    "* In the last code cell, uncomment the `which=random` line\n",
    "* Repeatedly run the last cell to generate a new grid of random results, until 4 incorrect predictions are shown.\n",
    "* Submit your notebook with your grid containing $\\ge 4$ incorrect predictions.\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Go back to the cells above in the 'Structure the Network' section. \n",
    "* Set the size of the middle layer to 16, 32, 64, 128 nodes and re-execute the cell.\n",
    "* Set the number of training epochs to 1, 3, 5 and re-execute the cell.\n",
    "* Re-execute the cell that evaluates the model on the test data.\n",
    "\n",
    "For each of those 4x3 runs, populate statistics into a spreadsheet with these columns:\n",
    "* Nodes (middle layer)\n",
    "* Epochs\n",
    "* Accuracy (Train)\n",
    "* Loss (Train)\n",
    "* Accuracy (Test)\n",
    "* Loss (Test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "800Q2PNwJKCK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
