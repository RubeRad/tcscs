{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook for MNIST neural network\n",
    "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
    "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
    "  - For Markdown cells, 'execute' means render the formatting.\n",
    "  - For Code cells, 'execute' means run the python.\n",
    "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
    "1. Any cell can be edited (double-click into it) and re-executed (SHIFT-ENTER again).\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "This first code cell includes import statements, which set up libraries of ready-to-go capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random                      # so we can display random images from the dataset\n",
    "import numpy as np                 # numpy is everything with arrays and matrices, 'np' is a commonly-used nickname\n",
    "import matplotlib.pyplot as plt    # most common python graphing library\n",
    "import tensorflow as tf            # tensorflow is a deep learning framework.\n",
    "from   tensorflow   import keras   # tensorflow.keras offers higher-level control of common tensorflow tasks\n",
    "from   sklearn      import metrics # we get the 'confusion_matrix' function from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow keras library includes some datasets for training. The Modified National Institute of Standards and Technology (MNIST) dataset is 70000 images of handwritten numerical digits; each a 28x28 pixel image, and corresponding labels specifying the right answer for each.\n",
    "\n",
    "The dataset is pre-divided into 60000 images for training the neural network, and 10000 held back from the training set for independent testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataset, pre-divided into train/test, and labels for each\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Just a little data prep here, we scale the pixel values from the range 0..255 to 0..1.0 \n",
    "# (numpy makes it simple, every value in the 28x28 array gets scaled by the one divisor).\n",
    "\n",
    "train_images = train_images / 255.0  # rescale from 0..255 to 0..1.0\n",
    "test_images  = test_images  / 255.0 \n",
    "\n",
    "ntrain = len(train_images)\n",
    "ntest  = len(test_images)\n",
    "\n",
    "print(ntrain, 'training images')\n",
    "print(ntest,  'test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the data looks to Python\n",
    "What is Python holding in memory now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at a training image -- can you tell what it is?\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's what it is\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Go back and look at other images/labels in the training or testing set. Can you find any where the images are recognizable, maybe if the label says it should be a 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the data looks to humans\n",
    "Let's take a look at what some of these handwritten digits look like when displayed as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which = random.randint(0, ntrain-1)\n",
    "\n",
    "# Matplotlib can, instead of plot(), imshow() \n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.imshow(train_images[0])  # , cmap=plt.cm.binary)\n",
    "\n",
    "# ax.set_xticks( [] )\n",
    "# ax.set_yticks( [] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "* In the graphing cell above, uncomment the extra parts one by one, see what happens.\n",
    "* Change it to show an image from the test set instead of the training set\n",
    "* Use the next cell to define a function to draw a training or test image onto plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(ax, img, typ, idx, lbl):\n",
    "    \n",
    "    ax.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    ax.set_xticks( [] )\n",
    "    ax.set_yticks( [] )\n",
    "    \n",
    "    caption = '{}[{}] is a {}'.format(typ, idx, lbl)\n",
    "    ax.set_xlabel(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_image(ax, train_images[0], 'train', 0, train_labels[0])\n",
    "#plot_image(ax, test_images[0], 'test', 0, test_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a function to plot and caption a training image\n",
    "def plot_training_image(idx):\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    plot_image(ax, train_images[idx], 'train', idx, train_labels[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to make a function to plot and caption a test image\n",
    "def plot_test_image(idx):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test it\n",
    "plot_test_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python code renders 25 train_images in a 5x5 grid. In the middle of the loop you can switch between `which=i` and `which=random...` to control which 25 get displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows 5x5 training images (first 25 or random 25)\n",
    "plt.figure(figsize=(10,10))  # 10x10 'inches'\n",
    "for i in range(25):          # i = 0...24\n",
    "    # set up each next subplot\n",
    "    plt.subplot(5,5, i+1)    # in a 5x5 grid, setup subplot 1...25\n",
    "    ax = plt.gca()           # gca=get current axes, now for this new subplot\n",
    "    \n",
    "    # which training image to show?\n",
    "    which = i                            # show the ith training image\n",
    "    #which = random.randint(0,ntrain-1)  # show a random image\n",
    "    \n",
    "    plot_image(ax,                  # call the function we wrote before\n",
    "               train_images[which],\n",
    "               'train',\n",
    "               which,\n",
    "               train_labels[which])\n",
    "\n",
    "plt.show()  # after all 25 subplots are set up, show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Uncomment the `which = random` line, and regenerate a bunch more grids of digit images.\n",
    "\n",
    "Can you find some that look ambiguous and might be difficult? Make a note of the index, we can see later how the neural network does at recognizing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis\n",
    "## Structure the Network\n",
    "This is where we set up the structure of the neural network, and run the training. The model has 3 layers:\n",
    "\n",
    "1. The first/input `Flatten` layer maps the individual pixel values from their 28x28 grid to an array of 784 values.\n",
    "1. The second/middle layer is `Dense`, which means an arc from each of the 784 first-layer nodes, to each of the 2nd-layer nodes.   \n",
    "  * `relu` (\"rectified linear unit\") is the most common 'activation function', and all it does is check whether the sum of scaled/biased inputs is positive or not. \n",
    "  * If it is positive, it 'fires' by outputting that value. \n",
    "  * If it is negative, it doesn't fire (or rather, outputs the value 0).\n",
    "1. The third/output layer (also `Dense`) must have 10 nodes, because we are classifying the 10 different digits. \n",
    "  * `softmax` takes the 10 numerical values that accumulate in the 10 nodes, and rescales them so they are positive and sum to 1. \n",
    "  * This way we can interpret them as probabilities (of being various digits)\n",
    "\n",
    "Note for the middle layer we can choose more or fewer nodes, but the outer layers have to fit the input and output. Also we could add more intermediate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   # input  layer; one node per pixel\n",
    "    keras.layers.Dense(16, activation='relu'),    # middle layer; may be changed to more nodes\n",
    "    keras.layers.Dense(10, activation='softmax')  # output layer; must have 10 nodes because 10 digits\n",
    "])\n",
    "\n",
    "# 'compile' basically means get ready to run\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "This is where the computation happens:\n",
    "- Forward-propagation from pixel inputs through the network, to scores in the output layer\n",
    "- Comparison of scores to truth, yielding errors\n",
    "- Back-propagation from errors to update coefficients in the network\n",
    "\n",
    "The two output statistics are\n",
    "* **accuracy** the percentage of the 60000 training images predicted correctly. \n",
    "* **loss**: a penalty for not assigning probability 1 to the correct answer; see below\n",
    "\n",
    "The number of training epochs can be increased until convergence (the model stops improving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, \n",
    "          train_labels, \n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been trained, it's got weights -- scale factors for the edges, and biases for the nodes. Look at all the shapes of the parts of `model.weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Network\n",
    "Now that the model is trained (the network coefficients have been fit to the training data), we test it by evaluating on the test images it has never seen.\n",
    "\n",
    "Note that **accuracy** and **loss** are also computed to evaluate the performance of the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do those values of loss and accuracy on the *test* set, compare to loss and accuracy from the *training*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the predictions\n",
    "The point of the network is to predict what digit an image is. We can run the model on all the `test_images` and get all the predictions, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 0                             # first we'll look at test case 0\n",
    "#which = random.randint(0, ntest-1)   # later we can do random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictions[which]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is `predictions[0]`? How big is it? (Why is it that big?) What is it saying? Is this prediction correct?\n",
    "\n",
    "`predictions[0]` is supposed to predict the right answer for test case number 0. What is the right answer for test case number 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansa = test_labels[which]\n",
    "ansa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions[0]` is the neural network output layer, when `test_images[0]` is fed into the input layer of the network. What is `test_images[0]` anyways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to get matplotlib to show a picture of test_images[0]\n",
    "plot_test_image(which)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two kinds of printouts\n",
    "if pred == ansa:              # if the model predicted the right ansa        \n",
    "    p = 100 * preds[ansa]\n",
    "    print('The highest-probability prediction is {:.1f}% for {}, which is correct'.format(p,ansa))\n",
    "else:\n",
    "    p = 100 * preds[ansa]     # this is what we should have chosen\n",
    "    q = 100 * preds[pred]     # but this had a larger probability\n",
    "    print('The correct answer {} had probability {:.1f}%'.format(ansa, p))\n",
    "    print('But the prediction {} had probability {:.1f}%'.format(pred, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Prediction Scores\n",
    "This cell plots the predictions as a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "#ax.set_xticks(range(10)) # xticks at 0,1,...9, matching the digit labels\n",
    "\n",
    "barplot = plt.bar(range(10), preds, color=\"gray\")\n",
    "\n",
    "# remember 'pred' and 'ansa' that were set a few cells above?\n",
    "#barplot[pred].set_color('red')\n",
    "#barplot[ansa].set_color('blue')\n",
    "# why does this work? what happens if pred==ansa vs if pred!=ansa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand 'loss'\n",
    "If everything is working right, preds has a probability of 1 for the correct answer (and the bar graph has a near-1-height bar) . If the prediction probability for the right answer is less than 1, that is the basis for computing 'loss', as in the next cell. \n",
    "\n",
    "The reported 'loss' (along with accuracy) is the average of these values for all cases (across either the test set or training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = preds[ansa]  # remember ansa is the truth label (and the index of the truth label)\n",
    "q                # for a good prediction, this should be near 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the formula for loss\n",
    "loss = np.log2(1.0/q)    # If q is almost 1, this is almost 0. \n",
    "                         # The smaller q gets, the bigger 1/q gets, so the larger log(1/q) gets\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Repeat the cells above, setting which to a different index or letting it be random. Can you find any interesting cases which are wrongly-predicted, or more marginal than an easy correct prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "Here is the list of all the correct answers (most not printed, because 10,000 is too long!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels # these are the correct answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, each prediction is an array of 10 floating point numbers. This cell applies `argmax` to each to get the index of the largest score in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = predictions.argmax(axis=1) # these are the predictions; the index of the largest score for each test\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, first three predictions and the last three predictions match the truth. But since accuracy was not 100%, there are some mismatches in those 9994 that are not printed. \n",
    "\n",
    "The 'confusion matrix' generated by the next cell details which numbers were mistaken for which. The rows of the matrix mean 'which digit it actually is'. The columns mean 'which digit was predicted'. \n",
    "\n",
    "What is the meaning of the large diagonal values? Other than the upper-left value, what's the largest value in the first column? What does it mean? What's the largest off-diagonal value, and what does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize groups of results\n",
    "Below is more complex code that graphs a large number of test results, with the bar graph red to highlight wrong answers.\n",
    "\n",
    "The cells with `def` create functions (python analogues of Snap! custom blocks), and only have to be run once. The last block can be rerun many times, especially if `which` is set to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is very similar to the plot_image() function we made above\n",
    "# but with a more sophisticated caption\n",
    "def plot_image_cap(i, predictions_array, true_label, img):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)  # this shows the pixels\n",
    "\n",
    "    # the rest of this assembles the caption text\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    # this is the probability of whatever digit was predicted (right or wrong)\n",
    "    p = np.max(predictions_array)\n",
    "    \n",
    "    # this is the probability of predicting the right answer\n",
    "    q = predictions_array[true_label]\n",
    "    # if we chose the right answer, p==q\n",
    "    \n",
    "    # include the loss of this individual case in the caption\n",
    "    loss = np.log2(1.0/q) # the smaller the q, the larger the loss\n",
    "  \n",
    "    # assemble the caption by formatting values into a text string\n",
    "    caption = \"#{}({}) {:2.0f}% loss {:.3f}\".format(i,\n",
    "                                                    true_label,\n",
    "                                                    100*p, # 100* turns fractions into %\n",
    "                                                    loss)\n",
    "    # add the caption, with the appropriate color\n",
    "    plt.xlabel(caption, color=color) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the corresponding bar graph, red if it's wrong,\n",
    "# into the currently-selected subplot\n",
    "def plot_value_array(i, predictions_array, true_labels):\n",
    "  true_label = true_labels[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  #plt.yticks([])  # let there be yticks, so we can see the scale of the barplot\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This uses the functions above to graph images and bar graphs in a grid.\n",
    "# In the middle again choose either which=i for the first results, or which=random\n",
    "num_cols=4 # twice as many columns really, because a digit and a bar graph for each\n",
    "num_rows=6 # freals this many rows\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    which = i # as before, leave this for sequential, or uncomment the next line for random\n",
    "    #which = random.randint(0, len(test_images)-1)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)                                      # advance to the next subplot\n",
    "    plot_image_cap(which, predictions[which], test_labels[which], test_images[which]) # then plot in it\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(which, predictions[which], test_labels)    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "(See also Schoology)\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "* Make sure the network is structured with the middle Dense layer set to 16 nodes, and epochs to 1 (so that incorrect predictions are relatively common).\n",
    "  * If necessary, re-execute the Structure/Train/Evaluate cells to (badly) retrain the network\n",
    "* In the last code cell, uncomment the `which=random` line\n",
    "* Repeatedly run the last cell to generate a new grid of random results, until 4 incorrect predictions are shown.\n",
    "* Submit a screenshot of the grid (right-click, Save Image As...)\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Go back to the cells above in the 'Structure the Network' section. \n",
    "* Set the size of the middle layer to 16, 32, 64, 128 nodes and re-execute the cell.\n",
    "* Set the number of training epochs to 1, 3, 5 and re-execute the cell.\n",
    "* Re-execute the cell that evaluates the model on the test data.\n",
    "\n",
    "For each of those 4x3 runs, populate statistics into a spreadsheet with these columns:\n",
    "* Nodes (middle layer)\n",
    "* Epochs\n",
    "* Accuracy (Train)\n",
    "* Loss (Train)\n",
    "* Accuracy (Test)\n",
    "* Loss (Test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
