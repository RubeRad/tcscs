{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook for MNIST neural network\n",
    "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
    "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
    "  - For Markdown cells, 'execute' means render the formatting.\n",
    "  - For Code cells, 'execute' means run the python.\n",
    "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
    "1. Any cell can be edited (double-click into it) and re-executed (SHIFT-ENTER again).\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "This first code cell includes import statements, which set up libraries of ready-to-go capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random                    # so we can display random images from the dataset\n",
    "import numpy as np               # numpy is everything with arrays and matrices, 'np' is a commonly-used nickname\n",
    "import matplotlib.pyplot as plt  # most common python graphing library\n",
    "import tensorflow as tf          # tensorflow is a deep learning framework.\n",
    "from   tensorflow import keras   # tensorflow.keras offers higher-level control of common tensorflow tasks\n",
    "from      sklearn import metrics # we get the 'confusion_matrix' function from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow keras library includes some datasets for training. The Modified National Institute of Standards and Technology (MNIST) dataset is 70000 images of handwritten numerical digits; each a 28x28 pixel image, and corresponding labels specifying the right answer for each.\n",
    "\n",
    "The dataset is pre-divided into 60000 images for training the neural network, and 10000 held back from the training set for independent testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataset, pre-divided into train/test, and labels for each\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Just a little data prep here, we scale the pixel values from the range 0..255 to 0..1.0 \n",
    "# (numpy makes it simple, every value in the 28x28 array gets scaled by the one divisor).\n",
    "\n",
    "train_images = train_images / 255.0  # rescale from 0..255 to 0..1.0\n",
    "test_images  = test_images  / 255.0 \n",
    "\n",
    "print(len(train_images), 'training images')\n",
    "print(len(test_images),  'test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Data\n",
    "Let's take a look at what some of these handwritten digits look like. This python code plots 25 of them in a 5x5 grid. In the middle of the loop you can switch between `which=i` and `which=random...` to control which 25 get displayed.\n",
    "\n",
    "If you display enough random digits, can you find some that look ambiguous and might be difficult? Make a note of the index, we can see later how the network did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows 5x5 training images (first 25 or random 25)\n",
    "plt.figure(figsize=(10,10))  # 10x10 'inches'\n",
    "for i in range(25):          # i = 0...24\n",
    "    plt.subplot(5,5, i+1)    # in a 5x5 grid, setup subplot 1...25\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])           # don't use xticks, yticks, or grid\n",
    "    plt.yticks([])\n",
    "    which = i                                       # show the ith training image\n",
    "    #which = random.randint(0,len(train_images)-1)  # show a random image\n",
    "    plt.imshow(train_images[which], cmap=plt.cm.binary) # show image in plot\n",
    "    caption = 'train[{}] is a {}'.format(which, train_labels[which])\n",
    "    plt.xlabel(caption)        # caption with corresp. label\n",
    "plt.show()  # after all 25 subplots are set up, show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Uncomment the `which = random` line, and regenerate a bunch more grids of digit images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis\n",
    "### Structure the Network\n",
    "This is where we set up the structure of the neural network, and run the training. The model has 3 layers:\n",
    "\n",
    "1. The first/input `Flatten` layer maps the individual pixel values from their 28x28 grid to an array of 784 values.\n",
    "1. The second/middle layer is `Dense`, which means an arc from each of the 784 first-layer nodes, to each of the 2nd-layer nodes.   \n",
    "  * `relu` is the most common 'activation function', and all it does is check whether the sum of scaled/biased inputs is positive or not. \n",
    "  * If it is positive, it 'fires' by outputting that value. \n",
    "  * If it is negative, it doesn't fire.\n",
    "1. The third/output layer (also `Dense`) must have 10 nodes, because we are classifying the 10 different digits. \n",
    "  * `softmax` takes the 10 numerical values that accumulate in the 10 nodes, and rescales them so they are positive and sum to 1. \n",
    "  * This way we can interpret them as probabilities (ofbeing various digits)\n",
    "\n",
    "Note for the middle layer we can choose more or fewer nodes, but the outer layers have to fit the input and output. Also we could add more intermediate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   # input  layer; one node per pixel\n",
    "    keras.layers.Dense(16, activation='relu'),    # middle layer; may be changed to more nodes\n",
    "    keras.layers.Dense(10, activation='softmax')  # output layer; must have 10 nodes because 10 digits\n",
    "])\n",
    "\n",
    "# 'compile' basically means get ready to run\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network\n",
    "This is where the computation happens:\n",
    "- Forward-propagation from pixel inputs through the network, to scores in the output layer\n",
    "- Comparison of scores to truth, yielding errors\n",
    "- Back-propagation from errors to update coefficients in the network\n",
    "\n",
    "The two output statistics are\n",
    "* **accuracy** the percentage of the 60000 training images predicted correctly. \n",
    "* **loss**: a penalty for not assigning probability 1 to the correct answer; see below\n",
    "\n",
    "The number of training epochs can be increased until convergence (the model stops improving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(train_images, \n",
    "                    train_labels, \n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Network\n",
    "Now that the model is trained (the network coefficients have been fit to the training data), we test it by evaluating on the test images it has never seen.\n",
    "\n",
    "Note that **accuracy** and **loss** are also computed to evaluate the performance of the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Individual Results\n",
    "Now that we have applied the trained model to predict classifications for all the test data, let's take a look at a few to see how they compare to truth (the provided labels).\n",
    "\n",
    "### Output Layer Prediction Scores\n",
    "Set `which` variously and run the following cells to investigate.\n",
    "\n",
    "This first cell looks at the predictions array (the 10 numbers in the final layer of the network, after pushing the image through). The largest value is what digit is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the index of the first test image (python always counts starting from 0 not 1)\n",
    "which=0  # edit this to examine a specific \n",
    "# uncomment this to choose a random test case\n",
    "#which = random.randint(0,len(test_images)-1\n",
    "\n",
    "preds = predictions[which]    # grab this prediction, which is a 10-vector of scores from the final layer\n",
    "print('Predictions:', preds)  # let's see what it looks like!\n",
    "ansa = test_labels[which]     # this is the right answer\n",
    "pred = np.argmax(preds)       # 'max' is the largest *value* in preds, we want the *index* max lives at\n",
    "\n",
    "# two kinds of printouts\n",
    "if pred == ansa:              # if the model predicted the right ansa        \n",
    "    p = 100 * preds[ansa]\n",
    "    print('The highest-probability prediction is {:.1f}% for {}, which is correct'.format(p,ansa))\n",
    "else:\n",
    "    p = 100 * preds[ansa]     # this is what we should have chosen\n",
    "    q = 100 * preds[pred]     # but this had a larger probability\n",
    "    print('The correct answer {} had probability {:.1f}%'.format(ansa, p))\n",
    "    print('But the prediction {} had probability {:.1f}%'.format(pred, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Image\n",
    "This cell shows the image for test data 'which', using matplotlib similarly to above. Does it look like the prediction? If the prediction is wrong, does it make sense why it could have chosen that wrong prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure() # similar matplotlib setup as above to simply show the pixels \n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(test_images[which], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Prediction Scores\n",
    "This cell plots the predictions as a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid(False)\n",
    "plt.xticks(range(10)) # xticks at 0,1,...9, matching the digit labels\n",
    "#plt.yticks([])       # don't eliminate yticks, let them show percentages\n",
    "barplot = plt.bar(range(10), preds, color=\"gray\")\n",
    "# remember 'pred' and 'ansa' that were set a few cells above?\n",
    "barplot[pred].set_color('red')\n",
    "barplot[ansa].set_color('blue')\n",
    "# why does this work? what happens if pred==ansa vs if pred!=ansa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand 'loss'\n",
    "If everything is working right, preds has a probability of 1 for the correct answer (and the bar graph has a near-1-height bar) . If the prediction probability for the right answer is less than 1, that is the basis for computing 'loss', as in the next cell. \n",
    "\n",
    "The reported 'loss' (along with accuracy) is the average of these values for all cases (across either the test set or training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = preds[ansa]          # remember ansa is the truth label (and the index of the truth label)\n",
    "print(\"This digit is a {}; the model's score for that was {:.6f} (should be near 1.0)\".format(ansa, q))\n",
    "\n",
    "# This is the formula for loss\n",
    "loss = np.log2(1.0/q)    # If q is almost 1, this is almost 0. \n",
    "                         # The smaller q gets, the bigger 1/q gets, so the larger log(1/q) gets\n",
    "print('The average loss is {:.4f}; the loss that this case contributes is {:.6f}'.format(test_loss, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Repeat the cells above, setting which to a different index (any of the test images 0...9999), looking at the results for various test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Here is the list of all the correct answers (most not printed, because 10,000 is too long!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels # these are the correct answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, each prediction is an array of 10 floating point numbers. This cell applies `argmax` to each to get the index of the largest score in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = predictions.argmax(axis=1) # these are the predictions; the index of the largest score for each test\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, first three predictions and the last three predictions match the truth. But since accuracy was not 100%, there are some mismatches in those 9994 that are not printed. \n",
    "\n",
    "The 'confusion matrix' generated by the next cell details which numbers were mistaken for which. The rows of the matrix mean 'which digit it actually is'. The columns mean 'which digit was predicted'. \n",
    "\n",
    "What is the meaning of the large diagonal values? Other than the upper-left value, what's the largest value in the first column? What does it mean? What's the largest off-diagonal value, and what does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize groups of results\n",
    "Below is more complex code that graphs a large number of test results, with the bar graph red to highlight wrong answers.\n",
    "\n",
    "The cells with `def` create functions (python analogues of Snap! custom blocks), and only have to be run once. The last block can be rerun many times, especially if `which` is set to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots one image with a blue or red caption, \n",
    "# into the currently-selected subplot\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)  # this shows the pixels\n",
    "\n",
    "    # the rest of this assembles the caption text\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    # this is the probability of whatever digit was predicted (right or wrong)\n",
    "    p = np.max(predictions_array)\n",
    "    \n",
    "    # this is the probability of predicting the right answer\n",
    "    q = predictions_array[true_label]\n",
    "    # if we chose the right answer, p==q\n",
    "    \n",
    "    # include the loss of this individual case in the caption\n",
    "    loss = np.log2(1.0/q) # the smaller the q, the larger the loss\n",
    "  \n",
    "    # assemble the caption by formatting values into a text string\n",
    "    caption = \"#{}({}) {:2.0f}% loss {:.3f}\".format(i,\n",
    "                                                    true_label,\n",
    "                                                    100*p, # 100* turns fractions into %\n",
    "                                                    loss)\n",
    "    # add the caption, with the appropriate color\n",
    "    plt.xlabel(caption, color=color) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the corresponding bar graph, red if it's wrong,\n",
    "# into the currently-selected subplot\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  #plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This uses the functions above to graph images and bar graphs in a grid.\n",
    "# In the middle again choose either which=i for the first results, or which=random\n",
    "num_cols=4 # twice as many columns really, because a digit and a bar graph for each\n",
    "num_rows=6 # freals this many rows\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    which = i # as before, leave this for sequential, or uncomment the next line for random\n",
    "    #which = random.randint(0, len(test_images)-1)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)                                      # advance to the next subplot\n",
    "    plot_image(which, predictions[which], test_labels[which], test_images[which]) # then plot in it\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(which, predictions[which], test_labels)    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "(See also Schoology)\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Go back to the cells above in the 'Neural Network Analysis' section. \n",
    "* Set the size of the middle layer to 16, 32, 64, 128 nodes and re-execute the cell.\n",
    "* Set the number of training epochs to 1, 3, 5 and re-execute the cell.\n",
    "* Re-execute the cell that evaluates the model on the test data.\n",
    "\n",
    "For each of those 4x3 runs, populate statistics into a spreadsheet with these columns:\n",
    "* Nodes (middle layer)\n",
    "* Epochs\n",
    "* Accuracy (Train)\n",
    "* Loss (Train)\n",
    "* Accuracy (Test)\n",
    "* Loss (Test)\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "* Reset the middle Dense layer to 16 nodes, and epochs to 1, so that incorrect predictions are more common.\n",
    "* Re-execute the Structure/Train/Evaluate cells to (badly) retrain the network\n",
    "* In the last code cell, uncomment the `which=random` line\n",
    "* Repeatedly run the last cell to generate a new grid of random results, until 4 incorrect predictions are shown.\n",
    "* Submit a screenshot of the grid (right-click, Save Image As...)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
