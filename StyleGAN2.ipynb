{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/StyleGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StyleGAN2\n",
        "\n",
        "This notebook is adapted from [this notebook published by Mikael Christensen](https://t.co/hvB4OHthB5). For information on StyleGAN2, see:\n",
        "\n",
        "* Paper: https://arxiv.org/abs/1812.04948\n",
        "* Video: https://youtu.be/kSLJriaOumA\n",
        "* Code: https://github.com/NVlabs/stylegan\n",
        "* FFHQ: https://github.com/NVlabs/ffhq-dataset\n"
      ],
      "metadata": {
        "id": "c6iMA6QfJMec"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# Setup Cells\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are a handful of cells which need to be run first, to get things ready.\n",
        "\n",
        "If you come back to this notebook, you can collapse this setup section, and run all the hidden cells with one click"
      ],
      "metadata": {
        "id": "ShIBa9nIiZPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 1: Import tensorflow and clone StyleGAN2 code from github\n",
        "\n",
        "After running this cell, check out what GPU device Google is letting your cloud computer use (for free)! Search for it on Amazon, how much does it cost to buy one?\n",
        "\n",
        "Also, note in the Files sidebar, there is now a directory stylegan2 -- that is code pulled down from the git repository posted by NVIDIA at https://github.com/NVlabs/stylegan2.git"
      ],
      "metadata": {
        "id": "5x4eOWgNKRoO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzDuIoMcqfBT"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# avoid recursive cloning if this cell is re-run\n",
        "# always start in top directory\n",
        "%cd /content\n",
        "\n",
        "# Download the StyleGAN2 code from github\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "\n",
        "# change into the repo directory, stay there for everything\n",
        "%cd /content/stylegan2\n",
        "!mkdir projection\n",
        "!mkdir projection/target\n",
        "!mkdir projection/out\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 2: Download pretrained model and import other modules\n",
        "\n",
        "This imports a whole bunch more standard modules (StyleGAN2 is not a standard module, which is why it was cloned from github, not just imported).\n",
        "\n",
        "Then it downloads one pretrained network; that's the setup of all the nodes, layers, weights, biases, activation function choices, etc. The comments list a large number of possible model choices, by default it chooses stylegan2-ffhq-config-f-pkl, which is for 1024x1024 images of faces."
      ],
      "metadata": {
        "id": "ZjGPkGUSLIJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwVXBFaSuoIU"
      },
      "outputs": [],
      "source": [
        "# Download the model of choice\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "# Choose between these pretrained models - I think 'f' is the best choice:\n",
        "\n",
        "# 1024×1024 faces\n",
        "# stylegan2-ffhq-config-a.pkl\n",
        "# stylegan2-ffhq-config-b.pkl\n",
        "# stylegan2-ffhq-config-c.pkl\n",
        "# stylegan2-ffhq-config-d.pkl\n",
        "# stylegan2-ffhq-config-e.pkl\n",
        "# stylegan2-ffhq-config-f.pkl\n",
        "\n",
        "# 512×384 cars\n",
        "# stylegan2-car-config-a.pkl\n",
        "# stylegan2-car-config-b.pkl\n",
        "# stylegan2-car-config-c.pkl\n",
        "# stylegan2-car-config-d.pkl\n",
        "# stylegan2-car-config-e.pkl\n",
        "# stylegan2-car-config-f.pkl\n",
        "\n",
        "# 256x256 horses\n",
        "# stylegan2-horse-config-a.pkl\n",
        "# stylegan2-horse-config-f.pkl\n",
        "\n",
        "# 256x256 churches\n",
        "# stylegan2-church-config-a.pkl\n",
        "# stylegan2-church-config-f.pkl\n",
        "\n",
        "# 256x256 cats\n",
        "# stylegan2-cat-config-f.pkl\n",
        "# stylegan2-cat-config-a.pkl\n",
        "network_pkl = \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "# If downloads fails, due to 'Google Drive download quota exceeded' you can try downloading manually from your own Google Drive account\n",
        "# network_pkl = \"/content/drive/My Drive/GAN/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import pickle\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ltutdy9Q9GQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 3: Define a bunch of useful python functions\n",
        "\n",
        "These were all from the original Mikael Christensen notebook"
      ],
      "metadata": {
        "id": "zUBg1AZQLxsL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxbhe4uLvF_a"
      },
      "outputs": [],
      "source": [
        "# Useful utility functions...\n",
        "\n",
        "# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_in_w_space(dlatents, truncation_psi=0.7):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    Gs_kwargs.truncation_psi = truncation_psi\n",
        "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "\n",
        "    imgs = []\n",
        "    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n",
        "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
        "        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n",
        "        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n",
        "        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n",
        "    return imgs       \n",
        "\n",
        "def generate_images(zs, truncation_psi=0.7):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    if not isinstance(truncation_psi, list):\n",
        "        truncation_psi = [truncation_psi] * len(zs)\n",
        "        \n",
        "    imgs = []\n",
        "    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n",
        "        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n",
        "        noise_rnd = np.random.RandomState(1) # fix noise\n",
        "        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "def generate_zs_from_seeds(seeds):\n",
        "    zs = []\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "        zs.append(z)\n",
        "    return zs\n",
        "\n",
        "# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_from_seeds(seeds, truncation_psi):\n",
        "    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n",
        "\n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "\n",
        "        \n",
        "def clamp(x, minimum, maximum):\n",
        "    return max(minimum, min(x, maximum))\n",
        "    \n",
        "def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n",
        "  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n",
        "   \n",
        "  draw = ImageDraw.Draw(buffer)\n",
        "  cy = (y+y2)/2\n",
        "  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n",
        "  for i in range(len(latents)):\n",
        "    mx = x + (x2-x)*(float(i)/len(latents))\n",
        "    h = (y2-y)*latents[i]*0.1\n",
        "    h = clamp(h,cy-y2,y2-cy)\n",
        "    draw.line((mx,cy,mx,cy+h),fill=color)\n",
        "  return PIL.Image.alpha_composite(image,buffer)\n",
        "             \n",
        "  \n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n",
        "   return canvas\n",
        "\n",
        "def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n",
        "  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n",
        "  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "  for i in range(truncation_cutoff):\n",
        "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
        "    \n",
        "  return dlatent\n",
        "\n",
        "def generate_ws_from_zs(zs, truncation_psi=0.7, truncation_cutoff=9):\n",
        "  ws = []\n",
        "  for z in zs:\n",
        "    ws.append( convertZtoW(z, truncation_psi, truncation_cutoff) )\n",
        "  return ws\n",
        "\n",
        "def interpolate(zs, steps):\n",
        "   out = []\n",
        "   for i in range(len(zs)-1):\n",
        "    for index in range(steps):\n",
        "     fraction = index/float(steps-1) \n",
        "     #print('interpolate {}/{}'.format(index,steps-1))\n",
        "     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "   return out\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 4: Define some more python functions\n",
        "\n",
        "These are functions I wrote, to make it more straightforward to do the kinds of things I'm wanting students to do.\n",
        "\n",
        "Take a minute to look at the step-by-step working of `show_seeds()`"
      ],
      "metadata": {
        "id": "JCJRXgONL9gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_seeds(seeds):\n",
        "  # Use each seed to initialize the rng and sample latent vectors:\n",
        "  # 512 random variables from a Standard Normal distribution\n",
        "  zs = generate_zs_from_seeds(seeds)\n",
        "\n",
        "  # Map each latent vector into W-space that the generator accepts as input\n",
        "  ws = generate_ws_from_zs(zs)\n",
        "\n",
        "  # Push each W through the generator to yield an image\n",
        "  images = generate_images_in_w_space(ws)\n",
        "\n",
        "  # concatenate the images into a bigger gridded image\n",
        "  grid = createImageGrid(images, scale=0.7, rows=3)\n",
        "\n",
        "  # show them all!\n",
        "  imshow(grid)\n",
        "\n",
        "def seed2z(seed):\n",
        "  zs = generate_zs_from_seeds( [seed] )\n",
        "  return seeds[0]\n",
        "\n",
        "def seeds2imgs(seeds):\n",
        "  return generate_images_in_w_space( generate_ws_from_zs( generate_zs_from_seeds( seeds ) ) )\n",
        "\n",
        "def seed2img(seed):\n",
        "  imgs = seeds2imgs([seed])\n",
        "  return imgs[0]\n",
        "\n",
        "def show_seed_img(seed):\n",
        "  imshow(seed2img(seed))\n",
        "\n",
        "def w2img(wvec):\n",
        "  imgs = generate_images_in_w_space( [wvec] )\n",
        "  return imgs[0]\n",
        "\n",
        "def z2img(zvec):\n",
        "  ws = generate_ws_from_zs( [zvec] )\n",
        "  return w2img(ws[0])\n",
        "\n",
        "def show_z_img(latent):\n",
        "  imshow(z2img(latent))\n",
        "\n",
        "# For instance if you want to save a latent vector, dump(m_fave_z, 'myZ.pkl')\n",
        "# Then DOWNLOAD a copy of it, or it will be recycled along with the \n",
        "# ephemeral cloud computer\n",
        "def dump(thing, path):\n",
        "  with open(path, 'wb') as file:\n",
        "    pickle.dump(thing, file)\n",
        "\n",
        "# In a later Colab session, upload your file and you can load it back in\n",
        "# my_fave_z = load('myZ.pkl')\n",
        "def load(path):\n",
        "  with open(path, 'rb') as file:\n",
        "    thing = pickle.load(file)\n",
        "  return thing\n"
      ],
      "metadata": {
        "id": "Dpqf_-GvqrS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How a face is generated\n",
        "\n"
      ],
      "metadata": {
        "id": "tt9T94Q2el0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This is a close up look of elements in creating a random face. Later, these steps will be wrapped in functions, or we might jump into the process in the middle."
      ],
      "metadata": {
        "id": "AzTDQ91PigS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Generate a face: Step 1: choose a seed\n",
        "\n",
        "Choose any random number"
      ],
      "metadata": {
        "id": "5UCdmniO--LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1                              # first we'll all try this\n",
        "# seed = np.random.randint(10000000)  # then we'll try different random seeds\n",
        "seed"
      ],
      "metadata": {
        "id": "6Uqu7NelelDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Face: Step 2: seed the RNG\n",
        "\n",
        "Random Number Generators are typically deterministic, and if you initialize them with the same seed, they will reliably generate the same stream of randomness."
      ],
      "metadata": {
        "id": "jsZlEuV_fa7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(seed)"
      ],
      "metadata": {
        "id": "Xfe0oBLkfqZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Face Step 3: Randomly sample Z-space latent vector\n",
        "\n",
        "The z-vector needs to be a row-vector of 512 samples (dimension 1x512) of a Standard Normal ($\\mu=0$, $\\sigma=1$) random variable. `randn()` is the numpy function for the Standard Normal distribution (rand\"n\" is for Normal)"
      ],
      "metadata": {
        "id": "dIS8pOyDfzdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = rng.randn(1, 512)\n",
        "z"
      ],
      "metadata": {
        "id": "pDFilkYqf-am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "id": "4Nhr9cpNletW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Face Step 4: Convert latent vector from z-space to w-space\n",
        "\n",
        "The StyleGAN2 Generator network is two components: mapping (z-to-w) and synthesis (w-to-image). This step is basically just inputting the z vector into the mapping network, and out pops w. But there are some other details we won't get into, wrapped up in the convertZtoW function.\n",
        "\n",
        "The resulting w-space latent vector is shape (1,18,512). According to the StyleGAN2 paper, \"the synthesis network _g_ consists of 18 layers -- two for each resolution ($4^2$ -- $1024^2$)\" is probably where the 18 comes from.\n"
      ],
      "metadata": {
        "id": "MQU9rogzhInf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = convertZtoW(z)\n",
        "w\n"
      ],
      "metadata": {
        "id": "Mh4zzQCZhp3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape"
      ],
      "metadata": {
        "id": "0hk0PN9nibAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the differences between the values in the z vector, and the values in the w-vector (and these histograms say nothing about which of the 512 dimensions all the numerical values are)"
      ],
      "metadata": {
        "id": "Z2fui-oVaa9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By definition, a Standard Normal Bell Curve\n",
        "sns.histplot(z[0])"
      ],
      "metadata": {
        "id": "zbjnBQ1sZh12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(w[0,0])"
      ],
      "metadata": {
        "id": "aTpC7MPIZ_Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Face Step 5: Push the w-space vector through the synthesis network\n",
        "\n",
        "This is basically just inputting the w vector into StyleGAN2's synthesis network, and then the pixels of the output image can be read off the nodes in the output layer. This is wrapped up in function `generate_images_in_w_space`\n",
        "\n",
        "This function uses a progress bar, which is nice for later when generating multiple images"
      ],
      "metadata": {
        "id": "21ICv0hhjJiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = [w]                               # the function wants to be pased a list of w-space vectors...\n",
        "imgs = generate_images_in_w_space(ws)  #...and return a list of images"
      ],
      "metadata": {
        "id": "ewbF0TQ3jJV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Face Step 6: display the image\n",
        "\n",
        "The image display capability comes from `PIL` (python image library), again, we don't need to get into the details, it's wrapped up in function imshow"
      ],
      "metadata": {
        "id": "aWUj1LgYlCl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = imgs[0]  # we grab the first (i.e. one and only) image off the list\n",
        "imshow(img)"
      ],
      "metadata": {
        "id": "4hvr1gzfi6FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a Face Step 7: generate directly from z\n",
        "\n",
        "Function `convertZtoW()` does `Gs.component.mapping.run()` and function `generate_images_in_w_space()` does `Gs.component.synthesis.run()`, i.e. the two components of StyleGAN2 separately.\n",
        "\n",
        "The function `generate_images()` does both in one shot, using the whole network as `Gs.run()`"
      ],
      "metadata": {
        "id": "DKNATzVHl7v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zimgs = generate_images([z]) # this also wants a list of z vectors, and returns a list of images\n",
        "imshow(zimgs[0])"
      ],
      "metadata": {
        "id": "_Saj1JxTl7Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate lots of random faces\n"
      ],
      "metadata": {
        "id": "Rx9rpAluMUeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Take a look at how function `show_seeds()` does all the steps above (as well as assembling a list of images into a grid image).\n",
        "\n",
        "This cell uses chooses 9 random numbers and holds them in a list called `seeds`, and then shows them all with `show_seeds()`\n",
        "\n",
        "Take note of the extremely wide variety of faces generated! Age, gender, skin color, pose, expression, hairstyles/hats, glasses/earrings/etc. Once in a while, though, it goofs and there are noticeable defects, which often appear as water droplets, or in extreme cases, globs of electric blue goo."
      ],
      "metadata": {
        "id": "O2QAZtlOimV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate some random seeds\n",
        "seeds = np.random.randint(10000000, size=9)\n",
        "\n",
        "# print seeds in the same grid as the images\n",
        "print(np.array(seeds).reshape(3,3))  \n",
        "\n",
        "show_seeds(seeds)"
      ],
      "metadata": {
        "id": "UtLfilNLqGxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Z Interpolation\n"
      ],
      "metadata": {
        "id": "eIOEmPTQMOwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As seen above, an image can be generated starting from just a single number used to seed the rng, but what counts more is the latent vector z. \n",
        "\n",
        "It turns out, if you have any two latent vectors $z1$ and $z2$ (which generate two images img1 and img2), halfway between those vectors is an image which is 'halfway' between the images! Or $$z=\\frac{1}{10}z1 + \\frac{9}{10}z2$$ generates an image which is 10% of the way from the first image to the second, etc. \n",
        "\n",
        "A smooth path between the latent vectors, generates a smooth transition of generated images, which this next cell demonstrates."
      ],
      "metadata": {
        "id": "Pi0-V3YAirnb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aZvophLZQOw"
      },
      "outputs": [],
      "source": [
        "# Simple (Z) interpolation\n",
        "\n",
        "# these are the two seeds Christensen left in the notebook\n",
        "seeds = [5015289 , 9148088] # that hat tho!\n",
        "\n",
        "# You can try out any other two numbers you want, or let this choose randomly:\n",
        "#seeds = np.random.randint(10000000, size=2)\n",
        "\n",
        "# print the seeds in case you see an interesting face; just jot down the \n",
        "# seed and you'll be able to regenerate it later!\n",
        "print(seeds)\n",
        "\n",
        "# This does the same thing above to rng two latent vectors 'z' using the seeds\n",
        "z1, z2 = generate_zs_from_seeds(seeds)\n",
        "\n",
        "# The interpolate() function scales linearly from z1 to z2, and this renders \n",
        "# the resulting sequence of images\n",
        "number_of_steps = 9\n",
        "number_of_rows  = 3\n",
        "imgs = generate_images(interpolate([z1,z2], number_of_steps), 1.0)\n",
        "imshow(createImageGrid(imgs, 0.4 , number_of_rows))\n",
        "# If you want, you could change that from 9 steps, shown in rows of 3, to \n",
        "# 16 steps, shown in rows of 4, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework area\n"
      ],
      "metadata": {
        "id": "sA5FgFbipJQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Insert code/text cells as necessary to do the homework here, which is: \n",
        "\n",
        "1. Run the 9-random-image generation a bunch of times, and make note of two seeds which generate faces which are different in many different ways (age, gender, etc). \n",
        "1. Use two code cells with `show_seed()` to generate your two chosen images by themselves.\n",
        "1. Use another code cell to replicate the Z-interpolation code above and generate a **16-image** transition in a **4x4 grid**\n",
        "1. Conclude with a text cell where you briefly discuss your image choice, and how well the Z-transition worked."
      ],
      "metadata": {
        "id": "r8sgDzGKi1tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show your first image\n",
        "seed1 = "
      ],
      "metadata": {
        "id": "U7Ol1j20reXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show your 2nd image\n",
        "seed2 = "
      ],
      "metadata": {
        "id": "YnZ0DHygreHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a transition between them"
      ],
      "metadata": {
        "id": "nSzVRUHjrd5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss..."
      ],
      "metadata": {
        "id": "u1-fETRfrfbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Girl\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mEeI8TQgP0xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you sample all possible z-space vectors, and convert them into w-space vectors, and take the average, you get a 'mean face', which the paper says \"is similar for all trained networks, and the interpolation towards it never seems to cause artifacts.\""
      ],
      "metadata": {
        "id": "SUawObhdi7Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Girl Step 1: get the mean w-vector\n",
        "\n",
        "The network (`Gs`) holds onto the mean w-vector, we just need to grab it."
      ],
      "metadata": {
        "id": "FQg0MmOWA3lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meanw1 = Gs.get_var('dlatent_avg')\n",
        "meanw1.shape"
      ],
      "metadata": {
        "id": "KHNxAhGKZwle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Girl Step 2: copy 18 times\n",
        "\n",
        "That vector is only 512 numbers. We need to stack that vector 18 times to be able to generate images with it."
      ],
      "metadata": {
        "id": "kFTMfVljsi73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meanw = np.zeros(18*512).reshape(1,18,512) # this is the right shape, but all zeros\n",
        "# copy the 512-vector into each of the 18 spots\n",
        "for i in range(18):\n",
        "  meanw[0][i] = meanw1\n",
        "meanw.shape"
      ],
      "metadata": {
        "id": "oCrYug_vcVO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Girl Step 2: who is the Mean Girl?\n",
        "\n",
        "Let's take a look!"
      ],
      "metadata": {
        "id": "meLO416FtkUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = generate_images_in_w_space( [meanw] )\n",
        "imshow(imgs[0])"
      ],
      "metadata": {
        "id": "N3X9W3O8aM_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmmm, she doesn't look so mean after all!\n",
        "\n",
        "**What does it mean**, to say that that is the \"mean face\" of StyleGAN2?\n",
        "\n",
        "## Mean Girl Step 3: Pick a starting image\n",
        "\n",
        "Choose a seed, either one you liked from before, or a random one, preferably somebody that look very different from the Mean Girl."
      ],
      "metadata": {
        "id": "LdTjj2E_txhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 24687\n",
        "# seed = np.random.randint(10000000)\n",
        "print('Current seed is {}'.format(seed))\n",
        "zs = generate_zs_from_seeds( [seed] )\n",
        "ws = generate_ws_from_zs( zs )\n",
        "w1 = ws[0]\n",
        "imgs = generate_images_in_w_space(ws)\n",
        "imshow(imgs[0])"
      ],
      "metadata": {
        "id": "2EwPp5wub_ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Girl Step 4: compute w-space vector for \"Anti-Face\"\n",
        "\n",
        "Vectors (and matrices) are just piles of numbers, as long as any two vectors are the same shape, you can subtract them, term-by-term."
      ],
      "metadata": {
        "id": "ETNdTwaUudQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dw = meanw - w1     # thus dw is the 'direction' from w1 to meanw\n",
        "# meanw = w1 + dw   # this is just true, by rearranging the previous equation\n",
        "\n",
        "# But what if, starting at w1 and moving towards meanw, \n",
        "# we don't just stop there, but keep going!\n",
        "w2 = w1 + 2*dw\n"
      ],
      "metadata": {
        "id": "arVVdZoRanrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what does the anti-face look like?\n",
        "imgs = generate_images_in_w_space( [w2] )\n",
        "imshow(imgs[0])"
      ],
      "metadata": {
        "id": "RfhjOuoN2hSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Girl Step 5: display the Faces"
      ],
      "metadata": {
        "id": "mTL-Ier2x25R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This generates these three faces from their w-vectors\n",
        "imgs = generate_images_in_w_space( [w1, meanw, w2] )\n",
        "\n",
        "# scale=0.3 shrinks them so we can see together, and rows=1 will put them side-by-side\n",
        "gridImg = createImageGrid(imgs, scale=0.3, rows=1)\n",
        "\n",
        "imshow(gridImg)\n"
      ],
      "metadata": {
        "id": "buZr3YjTQ3yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Girl Step 6: Interpolate more smoothly between the face and anti-face\n",
        "\n",
        "The `interpolate()` function which was used up above to smoothly scale between z-space vectors, also works for w-space vectors"
      ],
      "metadata": {
        "id": "ZM7ioKsVzFVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = interpolate( [w1, w2], 9 )\n",
        "imgs = generate_images_in_w_space(ws)\n",
        "gridImg = createImageGrid(imgs, scale=0.4, rows=3)\n",
        "imshow(gridImg)"
      ],
      "metadata": {
        "id": "A6UVzk6IX1va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYdsgv4i6YPl"
      },
      "source": [
        "# Find Your Face!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "StyleGAN2 comes with a projector that finds the closest generatable image based on any input image. This allows you to get a feeling for the diversity of the portrait manifold.\n",
        "\n",
        "^That sentence is courtesy Mikael Christensen. What it means is, give it a picture of YOUR face (or maybe a celebrity you like) as a target, and it will search to find a w-space latent vector that generates an image as close as possible to that target. This is similar to iterative back-propagation, but adjusting the *inputs* rather than the *weights*."
      ],
      "metadata": {
        "id": "H8ytigWvjB1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face Step 1: Upload target image\n",
        "\n",
        "Look over to the left, in the Files sidebar. Expand directories **stylegan2/projection/target/.** Drag the image onto the target directory. \n",
        "\n",
        "(If you don't see it right away, try collapsing and re-expanding the directory)\n",
        "\n",
        "\n",
        "Only **ONE** image may be in the directory.\n",
        "\n",
        "The image needs to be a **color .png**, with a size of exactly 1024x1024 pixels. The\n",
        "image needs to have the eyes/mouth fairly-well aligned with the starting image \n",
        "for the search. A rule of thumb for that is to have about a finger's \n",
        "width of space below the chin, and a little bit of hair cut off the top. "
      ],
      "metadata": {
        "id": "Mn6__cz5Ujz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face Step 2: Find Your Face\n",
        "\n",
        "Run the cell below, which uses to the projector to execute the search.\n",
        "\n",
        "After a few seconds, you will see `0 / 1000`, and from there it takes about a second per step, so It will take maybe 10-15 minutes to complete.\n",
        "\n",
        "Unfortunately, you can't just walk away, because if the Colab Notebook finishes and then times out, it will be recycled, and your output along with it.\n",
        "\n",
        "While it's crunching, if you're curious, open up stylegan2/projection/out, and double-click on any image-stepNNNN.png to take a peek at its progress!"
      ],
      "metadata": {
        "id": "rG0zC0dbUlQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDLJBbpz6n4k"
      },
      "outputs": [],
      "source": [
        "# Convert uploaded images to TFRecords\n",
        "import dataset_tool\n",
        "dataset_tool.create_from_images(\"./projection/records/\", \"./projection/target/\", True)\n",
        "\n",
        "# Run the projector\n",
        "import projector\n",
        "import run_projector\n",
        "import training.dataset\n",
        "import training.misc\n",
        "import os \n",
        "\n",
        "print('Loading images from \"%s\"...' % 'records')\n",
        "dataset_obj = training.dataset.load_dataset(data_dir='projection', \n",
        "                                            tfrecord_dir='records', \n",
        "                                            max_label_size=0, \n",
        "                                            verbose=True, \n",
        "                                            repeat=False, \n",
        "                                            shuffle_mb=0)\n",
        "assert dataset_obj.shape == Gs.output_shape[1:]\n",
        "\n",
        "\n",
        "# Here we set up and use the projector\n",
        "proj = projector.Projector()\n",
        "proj.set_network(Gs)\n",
        "\n",
        "# for a full run this should be 1000, but it can be set smaller for testing\n",
        "proj.num_steps = 1000\n",
        "\n",
        "\n",
        "# 1000 is a lot of images, and they don't change that fast\n",
        "# only 'snapshot' (save out) every 10th one to put into the movie\n",
        "num_snapshots = int(proj.num_steps/10)\n",
        "\n",
        "images, _labels = dataset_obj.get_minibatch_np(1)\n",
        "images = training.misc.adjust_dynamic_range(images, [0, 255], [-1, 1])\n",
        "run_projector.project_image(proj, \n",
        "                            targets=images, \n",
        "                            png_prefix='projection/out/image-', \n",
        "                            num_snapshots=num_snapshots)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face: Step 3: Make a video\n",
        "\n",
        "Once the finding is done, the directory stylegan2/projection/out/ is full of images named `image-step0NNNN.png`, all the \"snapshots\" it saved along the journey to finding your face.\n",
        "\n",
        "This cell loads those image files and crunches them all together into a video, and saves out as a mp4 file. Each frame is the concatenation of the fixed target image on the left, and the current search step on the right. Note that the search starts at the Mean Face.\n",
        "\n",
        "If you want the saved filename to be something different than `movie.mp4`, you can edit the `movieName` variable."
      ],
      "metadata": {
        "id": "wH26aJUSWD_D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmjPpjFU6yq3"
      },
      "outputs": [],
      "source": [
        "# Create video \n",
        "\n",
        "import glob\n",
        "\n",
        "imgs = sorted(glob.glob(\"projection/out/*step*.png\"))\n",
        "\n",
        "target_imgs = sorted(glob.glob(\"projection/out/*target*.png\"))\n",
        "assert len(target_imgs) == 1, \"More than one target found?\"\n",
        "target_img = imageio.imread(target_imgs[0])\n",
        "\n",
        "movieName = \"projection/movie.mp4\"\n",
        "\n",
        "with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for filename in log_progress(imgs, name = \"Creating animation\"):\n",
        "        image = imageio.imread(filename)\n",
        "\n",
        "        # Concatenate images with original target image\n",
        "        w,h = image.shape[0:2]\n",
        "        canvas = PIL.Image.new('RGBA', (w*2,h), 'white')\n",
        "        canvas.paste(Image.fromarray(target_img), (0, 0))\n",
        "        canvas.paste(Image.fromarray(image), (w, 0))\n",
        "\n",
        "        writer.append_data(np.array(canvas))  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face: Step 4: Save your video\n",
        "\n",
        "Go find your video file on the File sidebar on the left, click '...', and Download. If you didn't change the filename away from movie.mp4, you have\n",
        "another opportunity to change the filename when you save the download."
      ],
      "metadata": {
        "id": "bSpp4Hc2Xfac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face: Step 5a: Save your W-space vector\n",
        "\n",
        "The next cell will save the W-space vector that the search finally settled on.\n",
        "Later you can reload it and display it again. The StyleGAN2 code typically calls\n",
        "this `dlatent` vs just `latent` for z\n",
        "\n",
        "***IMPORTANT*** Download a copy of this file! If you don't download it and the Colab session times out, it will be gone!"
      ],
      "metadata": {
        "id": "dBYjJY4J2kVQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk6aBG7H5I3G"
      },
      "outputs": [],
      "source": [
        "myW = proj.get_dlatents()\n",
        "\n",
        "# You can change this filename if you want\n",
        "filename = 'myWvector.pkl'\n",
        "\n",
        "dump(myW, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face: Step 5b: Reload your W-space vector\n",
        "\n",
        "If you are returning to this notebook with a saved W-space vector, you can load it back in, instead of the long process to search for a near-match.\n",
        "\n",
        "First upload your saved file to the colab session."
      ],
      "metadata": {
        "id": "3QhuYvXU31SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this filename to match what you uploaded\n",
        "filename = 'myWvector.pkl'\n",
        "\n",
        "myW = load(filename)"
      ],
      "metadata": {
        "id": "WYEH2nrZ4U4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Face: Step 6: Save your image\n",
        "\n",
        "In addition to the side-by-side video from above, you can also save just an image."
      ],
      "metadata": {
        "id": "cP6_-A3J5IQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvLEQCI96Med"
      },
      "outputs": [],
      "source": [
        "# This actually creates a list of images\n",
        "imgs = generate_images_in_w_space([myW])\n",
        "me = imgs[0]\n",
        "imshow(me)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change this if you want\n",
        "imgFilename = 'me.png'\n",
        "\n",
        "me.save(imgFilename)"
      ],
      "metadata": {
        "id": "K_EXh65z6Z2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework Area\n",
        "\n"
      ],
      "metadata": {
        "id": "GyqE_EHxX-Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two options for homework:\n",
        "\n",
        "1. Generate your anti-face. Start with `w1` as w for your face from the previous homework, and follow the steps above to compute `w2` for your anti-face, and generate a transition grid through the Mean Girl. (You will need to rerun some of the cells above to set `meanw` as well). **Discuss** what visible features of the result make that face the 'opposite' of yours. NOTE: a full 2 vectors away from yourself is probably TOO FAR beyond the Mean Girl on the other side. Scale down the factor of 2.0 until the end point still looks like a human being.\n",
        "\n",
        "2. Morph yourself into a hero. Repeat the Find Your Face process to obtain a w-vector for the face of somebody you want to morph into, and create a transition grid (or if you're ambitius, video!) that morphs you into your hero! \n",
        "Let me know if you need help cropping/resampling your hero's face to a 1024x1024 png to start with. Discuss: did the transition go near the Mean Girl (or close)? Why/why not?"
      ],
      "metadata": {
        "id": "aNGBcdXwjHRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do the homework here, add more cells as necessary"
      ],
      "metadata": {
        "id": "4xyr0xMdaCMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss..."
      ],
      "metadata": {
        "id": "VtBnCPnjjPyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boundary Vectors\n",
        "\n"
      ],
      "metadata": {
        "id": "-NzuXpPNIvjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In w-space, the vectors/points which generate images of various 'styles' (age, gender, etc) are well-separated into clusters, and we can use the vector between clusters to transition w-vectors forwards or backwards in that style"
      ],
      "metadata": {
        "id": "fUSczwHcjb31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Vectors Step 1: Upload vector data\n",
        "\n",
        "Thanks to [github user a312863063](https://github.com/a312863063/generators-with-stylegan2/tree/master/latent_directions), there are lots of 'latent directions' to try out. Upload all the provided *.npy.txt files into the stylegan2/ directory"
      ],
      "metadata": {
        "id": "K94jRsp1NYLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Vectors Step 2: Choose a 'style'\n",
        "\n",
        "Choose one of the *.npy.txt files and load it up."
      ],
      "metadata": {
        "id": "CnVXE3vgMIoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note as-is it's just a list of 18*512 numbers, \n",
        "# the reshape gets it ready for StyleGAN2\n",
        "dw_age = np.loadtxt('age.npy.txt').reshape(1,18,512)"
      ],
      "metadata": {
        "id": "bNbdkyugFxir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Vectors Step 3: Choose a starting point\n",
        "\n",
        "Use the techniques you should be good at by now to choose a w-space vector to start from."
      ],
      "metadata": {
        "id": "0bZqJNUUN_3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = meanw\n",
        "\n",
        "# or start with a w computed from a random seed, or loaded from a FYF\n"
      ],
      "metadata": {
        "id": "6oKSHukVND6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Vectors Step 4: Modify the w-space vector\n",
        "\n",
        "Move some distance backward (-dw) and forward (+dw) from the starting point. Depending on what style is being modified, and where you're starting from, you might move different distances back and forward. Note also the vectors are pretty short, so you might need to scale it up a lot."
      ],
      "metadata": {
        "id": "JHAPO9o3OgeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = w + 2*dw_age\n",
        "w2 = w - 2*dw_age"
      ],
      "metadata": {
        "id": "ecinMQYrPLsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Vectors Step 5: Create an interpolated transition grid\n",
        "\n",
        "Now that we have endpoints in w-space, we can do the same interpolation as before."
      ],
      "metadata": {
        "id": "yLBhHxkOPTQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = interpolate( [w1, w2], 9)\n",
        "imgs = generate_images_in_w_space(ws)\n",
        "grid = createImageGrid(imgs, scale=0.3, rows=3)\n",
        "imshow(grid)"
      ],
      "metadata": {
        "id": "0ZDDPNFWN7vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework Area\n",
        "\n"
      ],
      "metadata": {
        "id": "JrU5B9ThPtdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the techniques demonstrated above, make at least three transition grids that you like, using different 'style' dimensions. (For the starting face(s) you can use any w you want, and they don't have to be the same every time)\n",
        "\n",
        "Don't adjust from the starting image so far forward/backward that endpoints look crazy (or at least comparably no crazier than the starting face)"
      ],
      "metadata": {
        "id": "4jfsYxQAjevp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C3OmkQvxJudl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SxVl8oo5JybM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "StyleGAN2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}