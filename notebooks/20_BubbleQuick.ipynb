{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669949de",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/notebooks/20_BubbleQuick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee2e92",
   "metadata": {
    "id": "a6ee2e92"
   },
   "source": [
    "# CSV Handling with Pandas\n",
    "\n",
    "We have already started to learn about how `matplotlib` can be used to create excellent charts and graphs, but that was using datasets that were small enough to be typed directly into the notebook.\n",
    "\n",
    "`pandas` is an elegant and efficient python module for slurping in arbitrarily large data files, and handling them by column *name* rather than by index *number* (i.e. pandas enables ***Literate Programming***)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b3d1b",
   "metadata": {
    "id": "033b3d1b"
   },
   "outputs": [],
   "source": [
    "# As usual, the first step is to import the required python libraries\n",
    "import numpy             as np    # all kinds of numerical and matrix capabilities in here\n",
    "import matplotlib.pyplot as plt   # this is for making charts and graphs\n",
    "import pandas            as pd    # for convenient handling of csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defbb83",
   "metadata": {
    "id": "3defbb83"
   },
   "source": [
    "# DataFrames\n",
    "The top-level datatype in pandas is a `DataFrame`. Think of it as one spreadsheet tab from Google Sheets or Microsoft Excel.\n",
    "\n",
    "When you ask `pandas` to read a data file, it returns a `DataFrame` object, so it is conventional to use a variable that has `df` in the name.\n",
    "\n",
    "As usual in a python notebook, if we just mention a variable at the end of a cell, the notebook tries to show it to us. A `DataFrame` can be quite big, so usually it shows just a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a78ea",
   "metadata": {
    "id": "a71a78ea"
   },
   "outputs": [],
   "source": [
    "# csv = comma-separated-value is the most common/simple type of data file\n",
    "# pandas can even reach out to URLs on the internet to slurp in data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RubeRad/tcscs/master/notebooks/bq25.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcefb3a",
   "metadata": {
    "id": "efcefb3a"
   },
   "source": [
    "## DataFrames as Objects\n",
    "I said above a `DataFrame` is an *object*. What it means to be an *object* in programming is to not just be a singular piece of data, but to have:\n",
    "* *attributes* or *elements* or *members* -- an object is an organized collection of not just one, but many data elements\n",
    "* *methods* or *functions* -- an object knows how to do certain things that are relevant to its nature\n",
    "\n",
    "A simpler way to think of it, an object is a bag of nouns and verbs.\n",
    "\n",
    "And like Plato's idealized concept of chair, the object *per se* is *abstract*. Every *instance* (concrete) of an object type has specific values of its attributes, and behaviors of its methods.\n",
    "\n",
    "For instance, if there were a software object called `Dog`, some of its attributes might be `color`,  or `breed`, and some of its functions might be `speak()`, or `is_hungry()`. A variable `fluffy` that is a Dog object might have attribute values of `color='white'`, `breed='toy pomeranian'`, and its `speak()` method might return `'yip'`. A  variable `spike` that is also a Dog object might have attribute values of `color='black'`, `breed='doberman pinscher'`, and its `speak()` method might return `'GRRR!'`.   (For all dogs, the `is_hungry()` method probably always returns `True`.)\n",
    "\n",
    "In python, you access/reference an attribute of a variable with a certain object type, by stating the name of the variable, then a `.`, then the name of the attribute. Here are a couple of the most interesting *attributes* of every `DataFrame` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22619b1d",
   "metadata": {
    "id": "22619b1d"
   },
   "outputs": [],
   "source": [
    "df.shape    # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb351db",
   "metadata": {
    "id": "3bb351db"
   },
   "outputs": [],
   "source": [
    "df.columns  # list of names of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f222b2",
   "metadata": {
    "id": "f6f222b2"
   },
   "source": [
    "Methods are not *accessed* or *referenced* as data that merely *is* something, but *invoked*, since they are functions that *do* something. Methods are invoked similarly to referencing attributes, but always with (). Methods can also accept input parameters inside the (), just like the \"`bare functions`\" we have already seen how to make in python with `def`.\n",
    "\n",
    "Here are a few of methods of the DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f723f16",
   "metadata": {
    "id": "6f723f16"
   },
   "outputs": [],
   "source": [
    "df.describe()    # a statistical description of the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dce3f3",
   "metadata": {
    "id": "78dce3f3"
   },
   "outputs": [],
   "source": [
    "df.info()        # a more computer-science kind of description centered on data types and storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1349fe",
   "metadata": {
    "id": "4f1349fe"
   },
   "source": [
    "Compare these three ways to print a selection of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8394e",
   "metadata": {
    "id": "e8b8394e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05686c19",
   "metadata": {
    "id": "05686c19"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6549b",
   "metadata": {
    "id": "9de6549b"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31656d25",
   "metadata": {
    "id": "31656d25"
   },
   "source": [
    "As you can see, `head()` and `tail()` default to showing the first/last 5 rows (you can put a different number into the () -- try it!); and just mentioning the `DataFrame` variable does a `head()` and a `tail()` -- all nicely formatted with bold and grey stripes for convenient reading in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c09fa1",
   "metadata": {
    "id": "91c09fa1"
   },
   "source": [
    "# DataFrame columns\n",
    "As we saw above, pandas is aware of the columns of the dataset, by their *names* (the string labels in the top row of the .csv file). You can refer to any particular column using square brackets, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d23f2",
   "metadata": {
    "id": "166d23f2"
   },
   "outputs": [],
   "source": [
    "df['ALGORITHM']  # try all the available column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bade6",
   "metadata": {},
   "source": [
    "## Column shorthand\n",
    "Pandas has syntax magic that supports a shorthand notation like this: easier to type and read! More Literate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ALGORITHM  # try all the available column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b697fb",
   "metadata": {},
   "source": [
    "The catch on that shorthand is, it doesn't work if the column names have spaces. But, column headers can be changed. Here's how:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coldict = {'ALGORITHM'             : 'ALG',\n",
    "           'NUMBER OF ELEMENTS'    : 'N',\n",
    "           'NUMBER OF COMPARISONS' : 'COMPS',\n",
    "           'NUMBER OF SWAPS'       : 'SWAPS' }\n",
    "df.rename(columns=coldict, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3190e3",
   "metadata": {
    "id": "7f3190e3"
   },
   "source": [
    "A `DataFrame` column is also an object (technically the name of the object is `Series`, but since you find the names of the `Series` with the `DataFrame` attribute `columns`, we'll just call them columns). As an object, a column also has some useful methods. `describe()`, invoked on a column, behaves analogously to being invoked on a whole `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try it again with all the new compact column names\n",
    "df.ALG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb52a0",
   "metadata": {
    "id": "4adb52a0"
   },
   "outputs": [],
   "source": [
    "df.ALG.describe()  # try all the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d55986",
   "metadata": {
    "id": "75d55986"
   },
   "source": [
    "Another very useful method available for column objects is `value_counts()` -- what is that explaining about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3917ec",
   "metadata": {
    "id": "ff3917ec"
   },
   "outputs": [],
   "source": [
    "df.ALG.value_counts() # try all the column names. When is value_counts() more/less useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883c233",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca4781",
   "metadata": {},
   "source": [
    "## Collapse this section for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647fe7c",
   "metadata": {},
   "source": [
    "Come back later when you have an idea what needs to be cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904216a",
   "metadata": {},
   "source": [
    "## N outliers\n",
    "\n",
    "Looking at the data, it's clear there is some with $n>100$; let's get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a291f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.N, df.COMPS, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814b0ee",
   "metadata": {},
   "source": [
    "A row slice can find which data elements have $n>100$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.N > 100 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dea37",
   "metadata": {},
   "source": [
    "While that slice shows us *the rows* themselves, what we need are those index numbers on the left, and we get that by just tacking `.index` on the back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add .index to the back of what we had before\n",
    "# and catch it in a variable\n",
    "tooBigIndex = df[ df.N > 100 ].index\n",
    "# and look at it\n",
    "tooBigIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63d043",
   "metadata": {},
   "source": [
    "Once we have the index list of the columns we don't want, we can give it to the `DataFrame.drop()` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab15649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(tooBigIndex)\n",
    "# alternative to inplace=True would be df.drop(tooBigIdx, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c38c3",
   "metadata": {},
   "source": [
    "Now we can see all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a90c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.N, df.COMPS, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2043f1d",
   "metadata": {},
   "source": [
    "## QuickSort Outliers\n",
    "\n",
    "Take a look at that weird point with $80<x<90$ and $1000<y<2000$ -- what *is* that? Let's find it, with a complex, multi-condition, row-slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = df[ df.N >= 80 ]\n",
    "# slice = df[ (df.N >= 80) & (df.N <= 90) ]\n",
    "# ...\n",
    "slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ (df.ALG=='QUICK') & ( ???? ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c665442",
   "metadata": {},
   "outputs": [],
   "source": [
    "badQuickIdx = ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa92014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop( ???? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c24818",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.N, df.COMPS, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4782f29",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "That first filter of $N>80$ reduced the matching rows down to 530. \n",
    "\n",
    "* Continue to add the other conditions until the problem row is evident -- what's going on?\n",
    "* Complete the filter in the following cell out all data rows that have that problem\n",
    "* Set the index of the bad rows, and then drop the bad rows\n",
    "* Plot again to see that the data looks cleaner!\n",
    "* Rerun the entire notebook\n",
    "  * After this cleaning, all the rest of the operations on df should still work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e233a",
   "metadata": {},
   "source": [
    "## Homework III: BubbleSort Outliers\n",
    "See that weird BubbleSort outlier with $x<40$ and $y>1000$? Use row-slicing to get eyes on it.\n",
    "\n",
    "All BubbleSort results should have `COMPS == N*(N-1)/2`. As above where we found and dropped the index of all bad QuickSort points, find and drop the index of all bad BubbleSort points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice df to isolate the outlier with x<40 and y>1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice df to find all bad BUBBLE rows with COMPS != N*(N-1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6628c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index of the previous cell into a variable, and drop it from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81984d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot your beautiful clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafabe4",
   "metadata": {
    "id": "3bafabe4"
   },
   "source": [
    "# Adding new columns with math\n",
    "One of the elementary uses for a spreadsheet is to populating a new column using cell formulas to combine columns that already exist. Analogously, pandas makes it very easy to create new columns from previous.\n",
    "\n",
    "Derived columns will appear in the list of columns like the ones read from the raw data, and have all the same methods available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7aa90e",
   "metadata": {
    "id": "6c7aa90e"
   },
   "outputs": [],
   "source": [
    "# OPS is the column we really care most about!\n",
    "df['OPS'] = df.COMPS + df.SWAPS # NOTE: column 'ops' doesn't exist yet so we can't use the shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef8a5e",
   "metadata": {
    "id": "e0ef8a5e"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa6077",
   "metadata": {
    "id": "39fa6077"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b713bb90",
   "metadata": {
    "id": "b713bb90"
   },
   "outputs": [],
   "source": [
    "# Now that 'ops' is a column name (without spaces), shortcut use is available!!\n",
    "df.OPS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c3b0c",
   "metadata": {
    "id": "2c6c3b0c"
   },
   "outputs": [],
   "source": [
    "df.OPS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bd7df",
   "metadata": {},
   "source": [
    "## Column slicing\n",
    "\n",
    "If your data has way more columns than you need, you can grab a *slice* of just the columns you care about. A *slice* is still a DataFrame, but it's more like a lens that focuses on just a portion of the data in the original DataFrame. Column slicing is analagous to hiding some columns in your spreadsheet that you don't want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A slice is like a lens that focuses on just part of a DataFrame\n",
    "df_n_ops = df[ ['N','OPS'] ]\n",
    "df_n_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0f483",
   "metadata": {},
   "source": [
    "# Matplotlib and Pandas: a match made in heaven!\n",
    "\n",
    "The whole point is that matplotlib can take columns from pandas, and use them for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.plot(df.N, df.OPS, 'ko')\n",
    "\n",
    "# it sure would be nice if we could plot the BUBBLE and the QUICK as separate series/colors!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e912fb",
   "metadata": {
    "id": "b7e912fb"
   },
   "source": [
    "# DataFrame rows and slicing\n",
    "\n",
    "Perhaps the most powerful and flexible aspect of pandas is that we can also slice subsets of the rows. This is analagous to applying a filter to spreadsheet rows, except in a spreadsheet you can only have one filter active at a time. With pandas, you should expect to be slicing DataFrames all the time; maintaining one gold copy of the whole, original data, and looking at it this way and that.\n",
    "\n",
    "Recall that `==` is asking a *question*. Before executing this next cell, consider, what would expect to be the answer to the question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293b18e",
   "metadata": {
    "id": "3293b18e"
   },
   "outputs": [],
   "source": [
    "df.ALG == 'BUBBLE' # == is always a question. \n",
    "# What is it asking?\n",
    "# What does the answer mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd00d6",
   "metadata": {
    "id": "5acd00d6"
   },
   "source": [
    "What is the size of that thing which is the answer to the question? What does it mean?\n",
    "\n",
    "We can catch the answer to the question in a variable. And then we can give that variable to the `DataFrame` object.\n",
    "\n",
    "Pandas is clever enough to understand that, when we use square brackets to give it a single string, we want that column. But if we give it a list of booleans that is the same length as the number of rows of data, it will line up the Trues/Falses with the rows, and give us back just the rows that are True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000668d",
   "metadata": {
    "id": "b000668d"
   },
   "outputs": [],
   "source": [
    "# We can catch the answer to the question in a variable\n",
    "bubblerows = (df.ALG=='BUBBLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2117c11",
   "metadata": {
    "id": "e2117c11"
   },
   "outputs": [],
   "source": [
    "df[bubblerows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087fb31",
   "metadata": {
    "id": "e087fb31"
   },
   "source": [
    "When pandas gives us back the selected rows (the requested 'slice' of the data), it gives us back another `DataFrame` object, and we can hold that sliced `DataFrame` in another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ff8d0",
   "metadata": {
    "id": "bb5ff8d0"
   },
   "outputs": [],
   "source": [
    "df_bubble = df[bubblerows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653ec5b",
   "metadata": {
    "id": "8653ec5b"
   },
   "outputs": [],
   "source": [
    "# Use this cell to examine the sliced DataFrame df_bubble\n",
    "# in all the ways we learned about up top with the full DataFrame df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea953c",
   "metadata": {
    "id": "d4ea953c"
   },
   "source": [
    "This slicing operation can also be done in a single python statement, like below. This is very common pattern, examine it closely and expect to do it a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23b229",
   "metadata": {
    "id": "bc23b229"
   },
   "outputs": [],
   "source": [
    "# notice this:   vvvvvvvvvvvvvvvvvv\n",
    "df_bubble = df[  df.ALG == 'BUBBLE'  ]\n",
    "# is the same as what we saved off into variable \"bubblerows\"\n",
    "# This time, we just wrap that with df[  ]\n",
    "# We get to skip a step, and one less variable hanging around\n",
    "# (and one less variable we need to think of a Literate Programming name for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805da88d",
   "metadata": {
    "id": "805da88d"
   },
   "outputs": [],
   "source": [
    "# In this cell, create a DataFrame slice df_quick to go with df_bubble\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331cf4fa",
   "metadata": {},
   "source": [
    "Good news is, slices are fully functional DataFrames as well, and can be used for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959bca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.plot(df_bubble.N, df_bubble.OPS, 'rx')\n",
    "# add to this plot the N,OPS for your new df_quick sliced DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8d122",
   "metadata": {
    "id": "75e8d122"
   },
   "source": [
    "# Slices are not for changing\n",
    "\n",
    "Recall that, for Bubble Sort, the expected number of total operations is `1.5*COMPS` (why?). So let's try adding an `EXP` column to `df_bubble` so we can graph that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36503207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bubble['EXP'] = df_bubble.COMPS * 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7963c1",
   "metadata": {
    "id": "bbe11aa3"
   },
   "source": [
    "Oopx! What happened there?\n",
    "\n",
    "A slice is not (normally) a separate copy of the data. To avoid wasting memory, when pandas gives a slice `DataFrame`, it is like a lens or a prism, that sees just the right part of the original data.\n",
    "\n",
    "When we try to create a new column in the *slice*, pandas says \"Wait a minute, how am I supposed to deal with this back in the original full `DataFrame`? If there's a new column EXP for everybody, what am I supposed to do for EXP on all the rows that are not in this slice? The hint on the right way to do this is in the error message:\n",
    "\n",
    "> `Try using .loc[row_indexer,col_indexer] = value instead`\n",
    "\n",
    "What we need to do is to get this `EXP` column into the original DataFrame, before we slice it Bubble vs Quick. In general, all the original and computed columns of the DataFrame should be finalized before any row-slicing begins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707c17e",
   "metadata": {},
   "source": [
    "# Creating new columns selectively\n",
    "\n",
    "We're going to build up an `EXP`ected column back in the original DataFrame, a step at a time:\n",
    "\n",
    "1. Create a new column simply with a nonsense value you can recognize as \"something went wrong\"\n",
    "2. Select the `BUBBLE` rows and set `EXP` in those rows with the appropriate formula\n",
    "3. Select the `QUICK` rows and set `EXP` in those rows with the appropriate formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcebe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EXP'] = -1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f317e",
   "metadata": {},
   "source": [
    "Next we need to choose which rows we want to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daab3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we still have this sticking around from above:\n",
    "# bubblerows = (df.ALG == 'BUBBLE')\n",
    "bubblerows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6242a8e",
   "metadata": {},
   "source": [
    "Then the pandas `loc[]` allows us to do things on only a certain 'location' of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#        which rows   which col    what to set it to\n",
    "#        vvvvvvvvvv    vvvvv       vvvvvvvvvvvvvv\n",
    "df.loc[  bubblerows,   'EXP'   ] = df.COMPS * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.EXP.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5af84",
   "metadata": {},
   "source": [
    "This can also be done in one step, by putting a row-selection `==` right inside the `.loc[ ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459459bf",
   "metadata": {
    "id": "459459bf"
   },
   "outputs": [],
   "source": [
    "# What is the EXPected number of QuickSort operations for N cards?\n",
    "# Hint: numpy offers a log-base-2 function called np.log2()\n",
    "\n",
    "df.loc[ ?whichrows? , ?whichcol? ] = ?what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5488ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this shows no -1/nonsense values left, we did it!\n",
    "df.EXP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adcff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.plot(df.N, df.OPS, 'bo')\n",
    "ax.plot(df.N, df.EXP, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0bb59",
   "metadata": {},
   "source": [
    "## Slice the finalized data\n",
    "\n",
    "After finishing all changes to the original DataFrame, then we can recreate any slices we need.\n",
    "\n",
    "In general, the order for any data analysis task should be:\n",
    "\n",
    "1. **Load** the raw DataFrame\n",
    "1. **Clean** the DataFrame\n",
    "   1. Find/fix/remove any erroneous data\n",
    "   1. Consider slicing columns to just what you'll need\n",
    "1. **Add columns**, either\n",
    "   1. Use simple formulas that apply to every row\n",
    "   1. Use `.iloc[]` to selectively build up columns\n",
    "1. **Analyze**\n",
    "   1. Create slices of the finalized data as needed\n",
    "   1. Make graphs from the whole data or the slices\n",
    "   \n",
    "When you discover in **Stage 4: Analyze** that you need to change the data, go back and add code to the Cleaning/Adding sections of the notebook, and rerun all the cells, so all your slices will be consistent with the underlying data, and each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the EXP column has been created, we are done messing with df\n",
    "# recreate the df_bubble and df_quick slices\n",
    "df_bubble = \n",
    "df_quick  = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef42581",
   "metadata": {
    "id": "bef42581"
   },
   "source": [
    "# Homework I\n",
    "\n",
    "## Slicing practice\n",
    "\n",
    "NOTES: \n",
    "* For each of these, you should think of a concise but not confusing variable name for the slice\n",
    "* None of these plots need to be pretty, just make sure they are scatter or line as appropriate\n",
    "\n",
    "1. Make a slice of all the quicksort rows with N between 15 and 25\n",
    "   1. Make a plot of x=N,y=OPS from the slice.\n",
    "1. Make a slice of `df` (the original full `DataFrame`) of rows with OPS between 100 and 200. \n",
    "   1. Make a plot of N,OPS from the slice.\n",
    "1. Make a new column in the original `df` called `SWAPS_PER_COMP` (df.SWAPS divided by df.COMPS)\n",
    "   1. Or if you want, more concisely named `SPC`? \n",
    "   1. Recreate the df_bubble/df_quick slices (unfortunately, new columns added to the original `DataFrame` do not magically show up in `df_bubble` and `df_quick`). \n",
    "   1. Make a plot x=df.N and two data series, SWAPS_PER_COMP for bubblesort vs quicksort.\n",
    "1. Make a plot of df_bubble actual vs expected, with different colors for points above/below the line:\n",
    "   1. Make a slice from `df_bubble` for which OPS is less than EXP\n",
    "   1. Make another slice for which OPS is more than EXP. \n",
    "   1. Make a plot with three series: expected curve from `df_bubble`, and the under/over slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc1611",
   "metadata": {
    "id": "43dc1611"
   },
   "outputs": [],
   "source": [
    "# HWI.1 could start by slicing a slice, like this:\n",
    "dfq_ge_15 =  df_quick[  df_quick.N >= 15 ]\n",
    "dfq_15_25 = dfq_ge_15[ dfq_ge_15.N <= 25 ]\n",
    "\n",
    "# But here's how to slice with multiple conditions in one step\n",
    "# The () are very important! If you wanted OR instead of AND it would be | instead of &\n",
    "df_q_15_25 = df_quick[  (df_quick.N >= 15) & (df_quick.N <= 25)  ]\n",
    "\n",
    "# then plot it with plt.plot(), no need for exquisite styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27130729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HWI.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HWI.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HWI.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea63c77f",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "The pandas `groupby()` function gives the ability to create a summary DataFrame, where each summary row represents a group of rows in the original DataFrame. \n",
    "\n",
    "The trick is, once you tell it one column to `groupby()`, you have to tell it what kind of summary calculation you want in the other columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04339a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This alone doesn't do much useful\n",
    "# it returns a 'DataFrameGroupBy object', waiting for instructions on\n",
    "# how to handle the other columns\n",
    "df_bubble.groupby('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bubavg = df_bubble.groupby('N').mean()\n",
    "bubavg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f03d1",
   "metadata": {},
   "source": [
    "## Avoiding the `numeric_only` warning\n",
    "\n",
    "That's an annoying warning message, which comes from the fact that the `mean()` grouper got mad that you asked it to average the 'ALG' column (what's the average of the words 'BUBBLE' and 'QUICK'?)\n",
    "\n",
    "Here are two ways to avoid the annoyance of the warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e35965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column-slice doesn't have the non-numeric ALG column\n",
    "bub_n_ops = df_bubble[ ['N','OPS'] ]\n",
    "bubavg = bub_n_ops.groupby('N').mean()\n",
    "bubavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numeric_only=True option gives pandas explicit permission to omit the ALG column\n",
    "bubavg = df_bubble.groupby('N').mean(numeric_only=True)\n",
    "bubavg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e4ef6c",
   "metadata": {},
   "source": [
    "## Dealing with the `groupby()` index\n",
    "\n",
    "Next problem, whatever column you used to `groupby()`, is no longer a **named** column in the summary DataFrame. You can tell by that **N** up above being printed lower than the rest of the columns. N is the `index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "bubavg.N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb55d4e",
   "metadata": {},
   "source": [
    "Way 1 of dealing with the problem is by using `.index` instead of the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df05d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.plot(df_bubble.N, df_bubble.OPS, 'bo', alpha=0.2)\n",
    "ax.plot(bubavg.index,      # <-------- .index instead of .N\n",
    "        bubavg.OPS, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e003275",
   "metadata": {},
   "source": [
    "Way two is by using the `reset_index()` function, which turns `N` back into a named column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a31faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                      vvvvvvvvvvvvvv\n",
    "bubavg = df_bubble.groupby('N').mean(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.plot(df_bubble.N, df_bubble.OPS, 'bo', alpha=0.2)   # alpha=1 is opaque, alpha=0 is invisible\n",
    "ax.plot(bubavg.N,       bubavg.OPS, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18781e04",
   "metadata": {},
   "source": [
    "## Other grouping functions\n",
    "\n",
    "Pandas offers a wide variety of useful statistical ways for `groupby()` to summarize rows:\n",
    "\n",
    "* `mean()`\n",
    "* `sum()`\n",
    "* `prod()`\n",
    "* `std()` (standard deviation)\n",
    "* `quantile(0.9)` (this would be 90th percentile, for instance)\n",
    "* `median()` (aka `quantile(0.5)`)\n",
    "* `min()` (aka `quantile(0.0)`)\n",
    "* `max()` (aka `quantile(1.0)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with this---------> vvvv\n",
    "summary = df_bubble.groupby('N').mean(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51efad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2560829",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot()\n",
    "ax.plot(df_bubble.N, df_bubble.OPS, 'bo', alpha=0.2)\n",
    "ax.plot(summary.N,     summary.OPS, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268627e",
   "metadata": {
    "id": "0268627e"
   },
   "source": [
    "# Homework II\n",
    "\n",
    "## Use matplotlib and pandas to make an excellent graph\n",
    "\n",
    "You will need to refer back to the Matplotlib Intro notebook for details about styling/formatting\n",
    "\n",
    "Make a graph that demonstrates the superiority of QuickSort over BubbleSort, including `ax.plot()` commands for all the following:\n",
    "\n",
    "1. Scatter for bubblesort data\n",
    "2. Scatter for quicksort data\n",
    "3. Line plot for the expected number of bubblesort operations\n",
    "4. Line plot for the expected number of quicksort operations\n",
    "  1. A line plot of the `EXP` column will NOT work\n",
    "  1. Refer back to the Matplotlib notebook for an example showing how to use `np.arange()` to create a tight series of X values, and then math out the Y series as a formula\n",
    "5. 75th percentile OPS for bubblesort (using `groupby().quantile(0.75)`)\n",
    "6. 75th percentile OPS for quicksort\n",
    "7. 25th percentile OPS for bubblesort\n",
    "8. 25th percentile OPS for quicksort\n",
    "\n",
    "Style this graph as well as possible, making choices for colors, markers, sizes, linestyles, legend, axis labels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add any extra slicing/groupby() in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5946936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to render the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a5aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
