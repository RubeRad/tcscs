{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/notebooks/60_Geopandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKvmu2sI43Kx"
      },
      "source": [
        "# Geopandas and Choropleth Charts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5yS9nZP43Kz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # these we've seen before\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import geopandas as gpd          # this is the point: pandas with geos!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dQRQoUe43Kz"
      },
      "source": [
        "# Geopandas data\n",
        "Geopandas is a layer on top of pandas, that can handle geographic polygons (or points) and make maps with them. Geopandas has a couple datasets built-in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avjaRkyi43K0"
      },
      "outputs": [],
      "source": [
        "gpd.datasets.available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tx3ITIC43K0"
      },
      "source": [
        "`naturalearth_lowres` contains the outlines of 177 countries around the world, as well a few more useful columns. Once we read it in, the result is a pandas DataFrame like we've seen before, except there's a `geometry` column which adds special capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2S4GnLc43K0"
      },
      "outputs": [],
      "source": [
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgY79Iex43K0"
      },
      "outputs": [],
      "source": [
        "world.continent.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6g7fvfQd43K0"
      },
      "outputs": [],
      "source": [
        "world.gdp_md_est.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5cIt-VI43K1"
      },
      "source": [
        "## Drawing as a map\n",
        "\n",
        "A geopandas dataframe has a .plot() function, which simply works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WX1zlA143K1"
      },
      "outputs": [],
      "source": [
        "world.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ualoopOw43K1"
      },
      "source": [
        "## Filtering rows\n",
        "This works the same way as we saw before with regular pandas DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0KXcB5_43K1"
      },
      "outputs": [],
      "source": [
        "noam = world[ world.continent == 'North America']\n",
        "noam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueu2Il1B43K2"
      },
      "outputs": [],
      "source": [
        "noam.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93VJiZzn43K2"
      },
      "outputs": [],
      "source": [
        "asia = world[ world.continent == 'Asia' ]\n",
        "asia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr-XOdeK43K2"
      },
      "outputs": [],
      "source": [
        "asia.plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBJotc_V43K2"
      },
      "outputs": [],
      "source": [
        "sixc = world[ world.continent != 'Antarctica' ]    # != means 'not-equal'\n",
        "sixc.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ8EdmED43K3"
      },
      "outputs": [],
      "source": [
        "# Exercise: create a filtered DataFrame the \"continent\" of 'Seven seas (open ocean)'\n",
        "# What is it?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljpzQFXw43K3"
      },
      "outputs": [],
      "source": [
        "# Exercise: create a filtered DataFrame containing any 1 country of your choosing\n",
        "# (filter using the 'name' or 'iso_a3' column instead of 'continent')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAjWm5t_43K3"
      },
      "source": [
        "## Combining plots\n",
        "\n",
        "This shows how geopandas can have multiple DataFrames (filters of the same DataFrame) onto the same map.\n",
        "\n",
        "Note the big difference is we have an Axes, and we tell each plot() that's where they should plot themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "PHiqoITr43K3"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(18,10))\n",
        "axes = fig.add_subplot()\n",
        "sixc.plot(ax=axes, color='lightgrey')\n",
        "\n",
        "# Uncomment these one at a time\n",
        "#asia.plot(ax=axes, color='green')\n",
        "#noam.plot(ax=axes, color='purple')\n",
        "#axes.set_xticks([])\n",
        "#axes.set_yticks([])\n",
        "#for s in axes.spines.values(): s.set_visible(False) # one-liner for turning off all 4 spines\n",
        "# don't indent after that line!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuiYZyhJ43K3"
      },
      "source": [
        "## Exercise 1: Filter and Color\n",
        "* Modify the code cells above to create filtered DataFrames as instructed\n",
        "* Color the 1 country in 'Seven seas (open ocean)' red -- where is it?\n",
        "* Color your chosen country blue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v60O_I443K3"
      },
      "source": [
        "## Mapping U.S. States\n",
        "There are datasets out there suitable for Geopandas for all kinds of countries, regions, and subdivisions. A very good collection [can be found here](https://github.com/deldersveld/topojson). If you need to work with any of those be sure to click to the 'Raw' view, then Save As...\n",
        "\n",
        "This file `us-albers.json` came from that repository. It has the U.S. states, with Alaska/Hawaii scaled/shifted as customary to make a more compact map.\n",
        "\n",
        "Note this has 51 'states' in it -- why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "0ER6Gxx943K3"
      },
      "outputs": [],
      "source": [
        "states = gpd.read_file('https://raw.githubusercontent.com/RubeRad/camcom/master/us-albers.json')\n",
        "states.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN1lWRdd43K4"
      },
      "outputs": [],
      "source": [
        "states.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj8GAMRQ43K4"
      },
      "outputs": [],
      "source": [
        "states.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgHtxdNW43K4"
      },
      "source": [
        "## Choropleth Maps\n",
        "The world 'choropleth' comes from Greek χῶρος (choros 'area/region') and (πλῆθος plethos 'multitude'). The main purpose (Greek τέλος) of Geopandas is choropleth maps. You just tell `plot()` what column you are interested in, and Geopandas will color each shape accordingly, using a color scheme/map based on the range of values it finds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGjQZVMR43K4"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "axes= fig.add_subplot()\n",
        "states.plot(column='census', ax=axes) # column 'census' is the population of each state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNgewHwZ43K4"
      },
      "source": [
        "## Exercise 2: Choropleth Options\n",
        "One at a time, add/change options to `states.plot()` above, and see what happens:\n",
        "* `cmap='Blues'` (or Reds, Greens,... or OrRd, YlGnBu, etc, see [Matplotlib colormaps](https://matplotlib.org/tutorials/colors/colormaps.html))\n",
        "* `edgecolor='k'`\n",
        "* `legend=True`\n",
        "* `legend_kwds={'orientation':'horizontal'}`\n",
        "* `scheme='quantiles'`\n",
        "* `legend_kwds={'loc':'lower left'}`\n",
        "* `legend_kwds={'loc':'lower left', 'bbox_to_anchor':(1,0)}`\n",
        "\n",
        "**Note** what happened there (if you did it right) is first the choropleth used a smooth, continuous range of colors from whatever cmap was chosen. `scheme='quantiles'` switched it to 5 discrete colors from that cmap, and it totally changed the type of legend.\n",
        "\n",
        "The first use of `'lower left'` referred to where within the whole plot to put the legend. When `'bbox_to_anchor'` was added, the meaning of `'lower left'` changed to which corner of the legend to anchor. And (1,0) means 100% of the way to the right of the plot, and 0% of the way up the plot -- the coordinates are not related to the coordinates being plotted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01JdGSZo43K5"
      },
      "source": [
        "# Combining DataFrames\n",
        "\n",
        "Usually the data you are analyzing is from a separate source, in its own DataFrame; the Geopandas mapping dataframe doesn't have that much information in it.\n",
        "\n",
        "In a normal case like that, you need to *merge* the data-DataFrame with the mapping-DataFrame, so that Geopandas can map the data you care about"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqmMZBJX43K5"
      },
      "source": [
        "## Merging Covid data to a world map\n",
        "We'll load the same Covid data we were looking at in the other recent notebook, and give it the same treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJMBH0t343K5"
      },
      "outputs": [],
      "source": [
        "# load it\n",
        "url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n",
        "dfall = pd.read_csv(url, parse_dates=['date']) # make sure it knows 'date' is dates\n",
        "dfall # take a look"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNdXQyVF43K5"
      },
      "outputs": [],
      "source": [
        "dfall.isnull().sum() # note some columns have some empty cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9w2pXH943K5"
      },
      "outputs": [],
      "source": [
        "# Fill in any missing values with 0\n",
        "dfall.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-wzKs3I43K5"
      },
      "outputs": [],
      "source": [
        "dfall.isnull().sum() # now they are all filled in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5YAutSA43K6"
      },
      "outputs": [],
      "source": [
        "# simplify to fewer columns\n",
        "df = dfall[ ['iso_code', 'location', 'date', 'new_cases', 'new_deaths', 'total_cases', 'total_deaths', 'population'] ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQcTzs_143K6"
      },
      "source": [
        "## Identify matching column\n",
        "In the `world` Geopandas DataFrame, the column with the 3-letter country codes is called `iso_a3`, and in the Covid DataFrame the column `iso_code` has the same country codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSVmelGB43K6"
      },
      "outputs": [],
      "source": [
        "world.iso_a3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOlqXob043K6"
      },
      "outputs": [],
      "source": [
        "df.iso_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U7KoXMb43K6"
      },
      "source": [
        "The `pd.merge()` command tells pandas to match rows up by those columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSOtrDnH43LD"
      },
      "outputs": [],
      "source": [
        "testmerge = pd.merge(world,  # this first DataFrame is on the Left\n",
        "                     df,     # this one is on the Right\n",
        "                     left_on='iso_a3',    # matching column in the Left\n",
        "                     right_on='iso_code') # matching column in the Right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDVrnslC43LD"
      },
      "outputs": [],
      "source": [
        "testmerge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyh6YE2C43LD"
      },
      "source": [
        "## Type, shape, and size\n",
        "Consider these questions:\n",
        "* What *is* `testmerge`?\n",
        "* What *shape* is `testmerge`?\n",
        "* What *size* is `testmerge`?\n",
        "\n",
        "`testmerge` has a `geometry` column, and a numerical column `total_cases` -- can we throw that data onto a map?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OANNYxLJ43LE"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "axes = fig.add_subplot()\n",
        "testmerge.plot(column='total_cases', ax=axes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cW4VlAe43LE"
      },
      "source": [
        "That didn't work (or at least not in a reasonable time). What might have gone wrong?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVqeCXsG43LE"
      },
      "outputs": [],
      "source": [
        "covidmax = df.groupby('iso_code').max(numeric_only=True)\n",
        "covidmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzn7OB8h43LE"
      },
      "outputs": [],
      "source": [
        "covidmrg = pd.merge(world, covidmax, left_on='iso_a3', right_on='iso_code')\n",
        "covidmrg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rwRIUEz43LE"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "axes = fig.add_subplot()\n",
        "covidmrg.plot(column='total_cases', ax=axes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoQPtNuf43LE"
      },
      "source": [
        "As before, this might need some per-capita treatment. Let's try this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEkM9ZID43LE"
      },
      "outputs": [],
      "source": [
        "df['cases_pct'] = df.total_cases / df.population * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fNy2un43LF"
      },
      "source": [
        "## Exercise 3:\n",
        "Go back up a bunch of cells and:\n",
        "\n",
        "* Comment out the testmerge and testmerge.plot() that didn't work\n",
        "* Add a new column to `dfall` `total_cases_pct` computing `total_cases` / `population` * 100\n",
        "* Re-column-slice `dfall`, adding `total_cases_pct` to the list of selected columns\n",
        "* Re-groupgy() `covidmax`\n",
        "* Re-merge `covidmrg`\n",
        "* Check the column `covidmrg.total_cases_pct` -- is it reasonable?\n",
        "* Make a choropleth of the `total_cases_pct` column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXpRVEnv43LF"
      },
      "source": [
        "## Mini-Exercise:\n",
        "What's going on here? Look at the total_cases/deaths and new_cases/deaths columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_ANJ9UD43LF"
      },
      "outputs": [],
      "source": [
        "covidmax = df.groupby('iso_code').max(numeric_only=True)\n",
        "covidmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQXtNTjv43LF"
      },
      "outputs": [],
      "source": [
        "covidsum = df.groupby('iso_code').sum(numeric_only=True)\n",
        "covidsum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM33Jlhn43LF"
      },
      "source": [
        "# State Shootings Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXWlIRQP43LF"
      },
      "outputs": [],
      "source": [
        "# All years\n",
        "wapoALL = pd.read_csv('https://corgis-edu.github.io/corgis/datasets/csv/police_shootings/police_shootings.csv')\n",
        "wapoALL.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T46t_t-B43LF"
      },
      "outputs": [],
      "source": [
        "# 2016 only\n",
        "wapo = wapoALL[ wapoALL['Incident.Date.Year'] == 2016 ]\n",
        "wapo.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab4yma7U43LG"
      },
      "outputs": [],
      "source": [
        "# Do these groupby().min() examples make sense?\n",
        "wapo.groupby('Incident.Location.State').min().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7Bn5eZn43LG"
      },
      "outputs": [],
      "source": [
        "# Do these groupby().max() examples make sense?\n",
        "wapo.groupby('Incident.Location.State').max().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeXjBrYj43LG"
      },
      "outputs": [],
      "source": [
        "# Do these groupby().mean() examples make sense?\n",
        "wapo.groupby('Incident.Location.State').mean(numeric_only=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldN61MNY43LG"
      },
      "source": [
        "For our purpose below, `count()` is most useful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwbxqYcw43LH"
      },
      "outputs": [],
      "source": [
        "# This time we'll save the grouped DataFrame in a variable, named state_counts\n",
        "# Note every column is countable, so every column gets counted, and yields the same count\n",
        "state_counts = wapo.groupby('Incident.Location.State').count().reset_index()\n",
        "state_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDUcr0Tw43LH"
      },
      "source": [
        "**Protip**: This took me some more googling to figure out. Note how way up there wapo.head() has a first column of row numbers not in any column, that's the *index*. But all these groupby() results have Incident.Location.State as the index. Unfortunately that seems to mean the DataSeries name can't be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSfVHVf543LH"
      },
      "outputs": [],
      "source": [
        "# This gives an error: \"Could not interpret input 'Incident.Location.State'\"\n",
        "sns.catplot(x='Incident.Location.State', y='Person.Name', data=state_counts, kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_lB_0Ux43LH"
      },
      "outputs": [],
      "source": [
        "# This is how to fix it, by copying the index column into a column with a name\n",
        "# Let's choose a name that's easier to type\n",
        "state_counts['state'] = state_counts.index\n",
        "state_counts.info() # See the extra DataSeries 'state' added to the end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGoSTsO743LH"
      },
      "source": [
        "Since all of the columns have the same counts, any is as good as any other. `Person.Name` holds the same counts as `Incident.Location.City`. But to make things less confusings, we can add a column with a better name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rECK9m6U43LH"
      },
      "outputs": [],
      "source": [
        "state_counts['n_shootings'] = state_counts['Person.Name']\n",
        "state_counts['n_shootings'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPAsGcqg43LI"
      },
      "outputs": [],
      "source": [
        "# With a column named n_shootings, this looks more sensible:\n",
        "sns.catplot(x='state', y='n_shootings', data=state_counts, kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KjJCo5h43LI"
      },
      "source": [
        "# Merging GeoDataFrames\n",
        "Remember from above how we merged `states` and `ev2016` into `all`? Well `all['iso_3166_2']` has 2-letter state abbreviations (inherited from `states`) that match `state_counts['state']` (inherited from `wapo`).\n",
        "\n",
        "That means we can also merge these together, so that other interesting columns (census (state population) and 2016 winning party (and `party_color`)) are available for sns/gpd plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4TU3RI443LI"
      },
      "outputs": [],
      "source": [
        "# Merge the WaPo shooting counts with the previous based on matching 2-letter code\n",
        "wapo_merge = pd.merge(all, state_counts, left_on='iso_3166_2', right_on='state')\n",
        "wapo_merge.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xymx19OG43LI"
      },
      "outputs": [],
      "source": [
        "# This is raw number of shootings, no accounting for state population\n",
        "wapo_merge.plot(column='n_shootings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZRSsf1Q43LI"
      },
      "outputs": [],
      "source": [
        "# This one also reads the csv off the web\n",
        "ev2016 = pd.read_csv('https://raw.githubusercontent.com/RubeRad/camcom/master/2016ev.csv')\n",
        "ev2016.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crO25IFM43LI"
      },
      "source": [
        "**Note** in our `states` DataFrame, the column with state names is `name`. In this new DataFrame, the column is named `State`. It is important that the values in the Series are spelled and punctuated and capitalized *exactly* the same, or that part of the data won't merge.\n",
        "\n",
        "After the merge, use `info()` and `head()` to verify that everything merged successfully -- same number of rows as before, and matched up properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqUCisW-43LI"
      },
      "outputs": [],
      "source": [
        "all = pd.merge(states, ev2016, left_on='name', right_on='State')\n",
        "all.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU8nrcme43LJ"
      },
      "outputs": [],
      "source": [
        "all.head() # scroll to the right to see the new columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRrSfZUg43LJ"
      },
      "source": [
        "**As seen above,** choropleths color regions based on values in a numerical column. However, what if the data is categorical?\n",
        "\n",
        "This shows an example of creating a new column with colors for categorical data, and having Geopandas map with those colors.\n",
        "\n",
        "Above we filtered out Asia and North America, and used the Geopandas `plot()` keyword `color` to draw each sub-DataFrame with a single color. We could do that here too, filter 'Winning Party'=='Republicans' or 'Democrats' and used two plot() statements, but if the number of categories gets larger, that gets awkward. So here's another way: we create a new column full of color names for Geopandas to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Tb78ux43LJ"
      },
      "outputs": [],
      "source": [
        "# 'red' and 'blue' is a little intense\n",
        "all['party_color'] = all['Winning Party'].map({'Republicans':'pink', 'Democrats':'lightblue'})\n",
        "all.head()\n",
        "# scroll right to see new column 'party_color'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSQ_G_k843LJ"
      },
      "outputs": [],
      "source": [
        "all['party_color'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIlSUzNG43LJ"
      },
      "outputs": [],
      "source": [
        "all.plot(color=all['party_color'], edgecolor='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9FOIF_N43LJ"
      },
      "source": [
        "## Exercise\n",
        "Using capabilities examined in the chloropleth exercise above make an excellent chloropleth visualization of `ev_per_million`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XfqE2HT843LK"
      },
      "outputs": [],
      "source": [
        "# Here's the new column: electoral votes per million people:\n",
        "all['ev_per_million'] = all['Votes'] / all['census'] * 1000000\n",
        "all['ev_per_million'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUfCsDZl43LK"
      },
      "source": [
        "# From Here:\n",
        "Either the bar plot above, or this map, can be tailored in all the ways demonstrated in the above examples. Some ideas:\n",
        "* Create a new column like shootings_per_million (see example ev_per_million above)\n",
        "  * Use that for either the map plot column, or the bar plot y\n",
        "\n",
        "For the bar plot:\n",
        "* Control the aspect and color\n",
        "* Sort the bars\n",
        "* Color bars by hue='Winning Party'\n",
        "  * (try palette='coolwarm', dodge=False)\n",
        "\n",
        "For the map plot:\n",
        "* Choose a useful palette from the link\n",
        "* Control the size/aspect\n",
        "* Add a legend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6zP2DOb43LK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}