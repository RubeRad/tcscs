{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/notebooks/60_Geopandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKvmu2sI43Kx"
   },
   "source": [
    "# Geopandas and Choropleth Charts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5yS9nZP43Kz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # these we've seen before\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import geopandas as gpd          # this is the point: pandas with geos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dQRQoUe43Kz"
   },
   "source": [
    "# Geopandas data\n",
    "Geopandas is a layer on top of pandas, that can handle geographic polygons (or points) and make maps with them. Geopandas has a couple datasets built-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avjaRkyi43K0"
   },
   "outputs": [],
   "source": [
    "gpd.datasets.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Tx3ITIC43K0"
   },
   "source": [
    "`naturalearth_lowres` contains the outlines of 177 countries around the world, as well a few more useful columns. Once we read it in, the result is a pandas DataFrame like we've seen before, except there's a `geometry` column which adds special capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2S4GnLc43K0"
   },
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgY79Iex43K0"
   },
   "outputs": [],
   "source": [
    "world.continent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6g7fvfQd43K0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "world.gdp_md_est.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5cIt-VI43K1"
   },
   "source": [
    "## Drawing as a map\n",
    "\n",
    "A geopandas dataframe has a .plot() function, which simply works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WX1zlA143K1"
   },
   "outputs": [],
   "source": [
    "world.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ualoopOw43K1"
   },
   "source": [
    "## Filtering rows\n",
    "This works the same way as we saw before with regular pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0KXcB5_43K1"
   },
   "outputs": [],
   "source": [
    "noam = world[ world.continent == 'North America']\n",
    "noam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueu2Il1B43K2"
   },
   "outputs": [],
   "source": [
    "noam.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93VJiZzn43K2"
   },
   "outputs": [],
   "source": [
    "asia = world[ world.continent == 'Asia' ]\n",
    "asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qr-XOdeK43K2"
   },
   "outputs": [],
   "source": [
    "asia.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBJotc_V43K2"
   },
   "outputs": [],
   "source": [
    "sixc = world[ world.continent != 'Antarctica' ]    # != means 'not-equal'\n",
    "sixc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJ8EdmED43K3"
   },
   "outputs": [],
   "source": [
    "# Exercise: create a filtered DataFrame the \"continent\" of 'Seven seas (open ocean)'\n",
    "# Plot it.\n",
    "# What is it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljpzQFXw43K3"
   },
   "outputs": [],
   "source": [
    "# Exercise: create a filtered DataFrame containing any 1 country of your choosing, and plot it\n",
    "# (filter using the 'name' or 'iso_a3' column instead of 'continent')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAjWm5t_43K3"
   },
   "source": [
    "## Combining plots\n",
    "\n",
    "This shows how geopandas can have multiple DataFrames (filters of the same DataFrame) onto the same map.\n",
    "\n",
    "Note the big difference is we have an Axes, and we tell each plot() that's where they should plot themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHiqoITr43K3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,10))\n",
    "axes = fig.add_subplot()\n",
    "sixc.plot(ax=axes, color='lightgrey')\n",
    "\n",
    "# Uncomment these one at a time\n",
    "#asia.plot(ax=axes, color='green')\n",
    "#noam.plot(ax=axes, color='purple')\n",
    "#axes.set_xticks([])\n",
    "#axes.set_yticks([])\n",
    "#for s in axes.spines.values(): s.set_visible(False) # one-liner for turning off all 4 spines\n",
    "# don't indent after that line!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuiYZyhJ43K3"
   },
   "source": [
    "## Exercise 1: Filter and Color\n",
    "* Modify the code cells above to create filtered DataFrames as instructed\n",
    "* Color the 1 country in 'Seven seas (open ocean)' red -- where is it?\n",
    "* Color your chosen country blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v60O_I443K3"
   },
   "source": [
    "## Mapping U.S. States\n",
    "There are datasets out there suitable for Geopandas for all kinds of countries, regions, and subdivisions. A very good collection [can be found here](https://github.com/deldersveld/topojson). If you need to work with any of those be sure to click to the 'Raw' view, then Save As...\n",
    "\n",
    "This file `us-albers.json` came from that repository. It has the U.S. states, with Alaska/Hawaii scaled/shifted as customary to make a more compact map.\n",
    "\n",
    "Note this has 51 'states' in it -- why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ER6Gxx943K3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "states = gpd.read_file('https://raw.githubusercontent.com/RubeRad/camcom/master/us-albers.json')\n",
    "states.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PN1lWRdd43K4"
   },
   "outputs": [],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mj8GAMRQ43K4"
   },
   "outputs": [],
   "source": [
    "states.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgHtxdNW43K4"
   },
   "source": [
    "## Choropleth Maps\n",
    "The world 'choropleth' comes from Greek χῶρος (choros 'area/region') and (πλῆθος plethos 'multitude'). The main purpose (Greek τέλος) of Geopandas is choropleth maps. You just tell `plot()` what column you are interested in, and Geopandas will color each shape accordingly, using a color scheme/map based on the range of values it finds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGjQZVMR43K4"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes= fig.add_subplot()\n",
    "states.plot(column='census', ax=axes) # column 'census' is the population of each state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNgewHwZ43K4"
   },
   "source": [
    "## Exercise 2: Choropleth Options\n",
    "One at a time, add/change options to `states.plot()` above, and see what happens:\n",
    "* `cmap='Blues'` (or Reds, Greens,... or OrRd, YlGnBu, etc, see [Matplotlib colormaps](https://matplotlib.org/tutorials/colors/colormaps.html))\n",
    "* `edgecolor='k'`\n",
    "* `legend=True`\n",
    "* `legend_kwds={'orientation':'horizontal'}`\n",
    "* `scheme='quantiles'`\n",
    "* `legend_kwds={'loc':'lower left'}`\n",
    "* `legend_kwds={'loc':'lower left', 'bbox_to_anchor':(1,0)}`\n",
    "\n",
    "**Note** what happened there (if you did it right) is first the choropleth used a smooth, continuous range of colors from whatever cmap was chosen. `scheme='quantiles'` switched it to 5 discrete colors from that cmap, and it totally changed the type of legend.\n",
    "\n",
    "The first use of `'lower left'` referred to where within the whole plot to put the legend. When `'bbox_to_anchor'` was added, the meaning of `'lower left'` changed to which corner of the legend to anchor. And (1,0) means 100% of the way to the right of the plot, and 0% of the way up the plot -- the coordinates are not related to the coordinates being plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01JdGSZo43K5"
   },
   "source": [
    "# Combining DataFrames\n",
    "\n",
    "Usually the data you are analyzing is from a separate source, in its own DataFrame; the Geopandas mapping dataframe doesn't have that much information in it.\n",
    "\n",
    "In a normal case like that, you need to *merge* the data-DataFrame with the mapping-DataFrame, so that Geopandas can map the data you care about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqmMZBJX43K5"
   },
   "source": [
    "## Merging Covid data to a world map\n",
    "We'll load the same Covid data we were looking at in the other recent notebook, and give it the same treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJMBH0t343K5"
   },
   "outputs": [],
   "source": [
    "# load it\n",
    "url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n",
    "dfall = pd.read_csv(url, parse_dates=['date']) # make sure it knows 'date' is dates\n",
    "dfall # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNdXQyVF43K5"
   },
   "outputs": [],
   "source": [
    "dfall.isnull().sum() # note some columns have some empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9w2pXH943K5"
   },
   "outputs": [],
   "source": [
    "# Fill in any missing values with 0\n",
    "dfall.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-wzKs3I43K5"
   },
   "outputs": [],
   "source": [
    "dfall.isnull().sum() # now they are all filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5YAutSA43K6"
   },
   "outputs": [],
   "source": [
    "# simplify to fewer columns\n",
    "df = dfall[ ['iso_code', 'location', 'date', 'new_cases', 'new_deaths', 'total_cases', 'total_deaths', 'population'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQcTzs_143K6"
   },
   "source": [
    "## Identify matching column\n",
    "In the `world` Geopandas DataFrame, the column with the 3-letter country codes is called `iso_a3`, and in the Covid DataFrame the column `iso_code` has the same country codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSVmelGB43K6"
   },
   "outputs": [],
   "source": [
    "world.iso_a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOlqXob043K6"
   },
   "outputs": [],
   "source": [
    "df.iso_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U7KoXMb43K6"
   },
   "source": [
    "The `pd.merge()` command tells pandas to match rows up by those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSOtrDnH43LD"
   },
   "outputs": [],
   "source": [
    "testmerge = pd.merge(world,  # this first DataFrame is on the Left\n",
    "                     df,     # this one is on the Right\n",
    "                     left_on='iso_a3',    # matching column in the Left\n",
    "                     right_on='iso_code') # matching column in the Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDVrnslC43LD"
   },
   "outputs": [],
   "source": [
    "testmerge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vyh6YE2C43LD"
   },
   "source": [
    "## Type, shape, and size\n",
    "Consider these questions:\n",
    "* What *is* `testmerge`?\n",
    "* What *shape* is `testmerge`?\n",
    "* What *size* is `testmerge`?\n",
    "\n",
    "`testmerge` has a `geometry` column, and a numerical column `total_cases` -- can we throw that data onto a map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OANNYxLJ43LE"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_subplot()\n",
    "testmerge.plot(column='total_cases', ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cW4VlAe43LE"
   },
   "source": [
    "That didn't work (or at least not in a reasonable time). What might have gone wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same-sizing before merging\n",
    "\n",
    "This is the most important lesson for successful use of geopanda:\n",
    "\n",
    "* Your pandas DataFrame with your data,\n",
    "* The geopandas DataFrame with the maps, and\n",
    "* The merged DataFrame that brings them together\n",
    "\n",
    "All have to have (about) the same size. I say \"about\" because there may be a few mismatches that dropped in the merge. But you cannot have a brazillion more rows in the data than the maps, because then the merge will have a brazillion rows, and the plot will try to draw a brazillion countries, or states. It will take forever, and it will be wrong, because it will just overdraw the same countries/states over and over, and what shows at the end is just whatever was last.\n",
    "\n",
    "Usually, the way to force a giant dataset to be (about) the same size as the mapping DataFrame, is to use `groupby` -- with the same column that was used for merging. Tips for `groupby()`:\n",
    "* After the `groupby('colname')` use a summarizing function, like max, min, mean, count, sum -- as appropriate.\n",
    "* Give the summarizing function the argument `numeric_only=True` otherwise it will complain like \"I don't know how to add strings!\"\n",
    "* End with `.reset_index()` to ensure the `groupby` column can still be used as a column, not just the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVqeCXsG43LE"
   },
   "outputs": [],
   "source": [
    "covidmax = df.groupby('iso_code').max(numeric_only=True).reset_index()\n",
    "covidmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yzn7OB8h43LE"
   },
   "outputs": [],
   "source": [
    "covidmrg = pd.merge(world, covidmax, left_on='iso_a3', right_on='iso_code')\n",
    "covidmrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rwRIUEz43LE"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_subplot()\n",
    "covidmrg.plot(column='total_cases', ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoQPtNuf43LE"
   },
   "source": [
    "As before, this might need some per-capita treatment. Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEkM9ZID43LE"
   },
   "outputs": [],
   "source": [
    "df['cases_pct'] = df.total_cases / df.population * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50fNy2un43LF"
   },
   "source": [
    "## Exercise 3:\n",
    "Go back up a bunch of cells and:\n",
    "\n",
    "* Comment out the testmerge and testmerge.plot() that didn't work\n",
    "* Add a new column to `dfall` `total_cases_pct` computing `total_cases` / `population` * 100\n",
    "* Re-column-slice `dfall`, adding `total_cases_pct` to the list of selected columns\n",
    "* Re-groupgy() `covidmax`\n",
    "* Re-merge `covidmrg`\n",
    "* Check the column `covidmrg.total_cases_pct` -- is it reasonable?\n",
    "* Make a choropleth of the `total_cases_pct` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXpRVEnv43LF"
   },
   "source": [
    "## Mini-Exercise:\n",
    "What's going on here? Look at the total_cases/deaths and new_cases/deaths columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_ANJ9UD43LF"
   },
   "outputs": [],
   "source": [
    "covidmax = df.groupby('iso_code').max(numeric_only=True)\n",
    "covidmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQXtNTjv43LF"
   },
   "outputs": [],
   "source": [
    "covidsum = df.groupby('iso_code').sum(numeric_only=True)\n",
    "covidsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HM33Jlhn43LF"
   },
   "source": [
    "# State Shootings Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXWlIRQP43LF"
   },
   "outputs": [],
   "source": [
    "# All years\n",
    "wapoALL = pd.read_csv('https://corgis-edu.github.io/corgis/datasets/csv/police_shootings/police_shootings.csv')\n",
    "wapoALL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T46t_t-B43LF"
   },
   "outputs": [],
   "source": [
    "# 2016 only\n",
    "wapo = wapoALL[ wapoALL['Incident.Date.Year'] == 2016 ]\n",
    "wapo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab4yma7U43LG"
   },
   "outputs": [],
   "source": [
    "# Do these groupby().min() examples make sense?\n",
    "wapo.groupby('Incident.Location.State').min().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7Bn5eZn43LG"
   },
   "outputs": [],
   "source": [
    "# Do these groupby().max() examples make sense?\n",
    "wapo.groupby('Incident.Location.State').max().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeXjBrYj43LG"
   },
   "outputs": [],
   "source": [
    "# Do these groupby().mean() examples make sense?\n",
    "wapo.groupby('Incident.Location.State').mean(numeric_only=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldN61MNY43LG"
   },
   "source": [
    "For our purpose below, `count()` is most useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwbxqYcw43LH"
   },
   "outputs": [],
   "source": [
    "# This time we'll save the grouped DataFrame in a variable, named state_counts\n",
    "# Note every column is countable, so every column gets counted, and yields the same count\n",
    "# Also, even though python can't .add() non-numeric data, it can .count() it, \n",
    "# so you don't need numeric_only=True\n",
    "state_counts = wapo.groupby('Incident.Location.State').count()\n",
    "state_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSfVHVf543LH"
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=state_counts, x='Incident.Location.State', y='Person.Name', kind='bar')#, height=4, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGoSTsO743LH"
   },
   "source": [
    "Since all of the columns have the same counts, any is as good as any other. `Person.Name` holds the same counts as `Incident.Location.City`. But to make things less confusings, we can add a column with a better name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rECK9m6U43LH"
   },
   "outputs": [],
   "source": [
    "state_counts['n_shootings'] = state_counts['Person.Name']\n",
    "state_counts['n_shootings'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPAsGcqg43LI"
   },
   "outputs": [],
   "source": [
    "# With a column named n_shootings, this looks more sensible:\n",
    "sns.catplot(data=state_counts, x='Incident.Location.State', y='n_shootings', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electoral Votes example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZRSsf1Q43LI"
   },
   "outputs": [],
   "source": [
    "# This one also reads the csv off the web\n",
    "ev2016 = pd.read_csv('https://raw.githubusercontent.com/RubeRad/camcom/master/2016ev.csv')\n",
    "ev2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crO25IFM43LI"
   },
   "source": [
    "**Note** in our `states` DataFrame, the column with state names is `name`. In this new DataFrame, the column is named `State`. It is important that the values in the Series are spelled and punctuated and capitalized *exactly* the same, or that part of the data won't merge.\n",
    "\n",
    "After the merge, use `info()` and `head()` to verify that everything merged successfully -- same number of rows as before, and matched up properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqUCisW-43LI"
   },
   "outputs": [],
   "source": [
    "evmrg = pd.merge(states, ev2016, left_on='name', right_on='State')\n",
    "evmrg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iU8nrcme43LJ"
   },
   "outputs": [],
   "source": [
    "evmrg.head() # scroll to the right to see the new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRrSfZUg43LJ"
   },
   "source": [
    "**As seen above,** choropleths color regions based on values in a numerical column. However, what if the data is categorical?\n",
    "\n",
    "This shows an example of creating a new column with colors for categorical data, and having Geopandas map with those colors.\n",
    "\n",
    "Let's make a new column and use `.loc` to fill it with colors to plot with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evmrg['party_color'] = 'pink' # Red for Republicans, but a little less intense\n",
    "evmrg.loc[ evmrg['Winning Party']=='Democrats', 'party_color' ] = 'lightblue'\n",
    "evmrg.party_color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7Tb78ux43LJ"
   },
   "outputs": [],
   "source": [
    "evmrg.head()\n",
    "# scroll right to see new column 'party_color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIlSUzNG43LJ"
   },
   "outputs": [],
   "source": [
    "evmrg.plot(color=all['party_color'], edgecolor='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KjJCo5h43LI"
   },
   "source": [
    "# Merging GeoDataFrames\n",
    "The Washington Post data has 2-letter state abbreviations in `'Incident.Location.State'`, and the `states` mapping data has 2-letter state abbreviations in `'iso_3166_2'`, so we can merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4TU3RI443LI"
   },
   "outputs": [],
   "source": [
    "# Merge the WaPo shooting counts with the previous based on matching 2-letter code\n",
    "wapo_merge = pd.merge(states, state_counts, left_on='iso_3166_2', right_on='Incident.Location.State')\n",
    "wapo_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xymx19OG43LI"
   },
   "outputs": [],
   "source": [
    "# This is raw number of shootings, no accounting for state population\n",
    "wapo_merge.plot(column='n_shootings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course it would be more informative to graph per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo_merge['n_per_cap'] = wapo_merge.n_shootings / wapo_merge.census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo_merge.plot(column='n_per_cap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9FOIF_N43LJ"
   },
   "source": [
    "## Exercise\n",
    "Using capabilities examined in the chloropleth exercise above make an excellent chloropleth visualization of `ev_per_million`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfqE2HT843LK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here's the new column: electoral votes per million people:\n",
    "evmrg['ev_per_million'] = evmrg['Votes'] / evmrg['census'] * 1000000\n",
    "evmrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=evmrg, x='iso_3166_2', y='ev_per_million', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evmrg.plot('ev_per_million')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUfCsDZl43LK"
   },
   "source": [
    "# From Here:\n",
    "Either the bar plot above, or this map, can be tailored in all the ways demonstrated in the above examples. Some ideas:\n",
    "* Create a new column like shootings_per_million (see example ev_per_million above)\n",
    "  * Use that for either the map plot column, or the bar plot y\n",
    "\n",
    "For the bar plot:\n",
    "* Control the aspect and color\n",
    "* Sort the bars\n",
    "* Color bars by hue='Winning Party'\n",
    "  * (try palette='coolwarm', dodge=False)\n",
    "\n",
    "For the map plot:\n",
    "* Choose a useful palette from the link\n",
    "* Control the size/aspect\n",
    "* Add a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6zP2DOb43LK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
