{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqN8q3LXUjew"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SS2l608QUjex"
   },
   "source": [
    "# Cleaning outliers\n",
    "\n",
    "The cars dudes have this problem, maybe you do too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_s_XA_7hUjey"
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv('https://corgis-edu.github.io/corgis/datasets/csv/cars/cars.csv')\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFTpkvrCUjez"
   },
   "outputs": [],
   "source": [
    "cars.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGwFWgCoUjez"
   },
   "source": [
    "Max highway mpg 223 !?!?!? That's gotta be a mistake. Here's how to find it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQhnXo8BUjez"
   },
   "outputs": [],
   "source": [
    "cars[ cars['Fuel Information.Highway mpg'] > 100 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ0pG91MUje0"
   },
   "source": [
    "...and fix it. Using that index right there and the column name, we can reach in and replace it with a reasonable value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CO4pSidUje0"
   },
   "outputs": [],
   "source": [
    "cars.at[3686, 'Fuel Information.Highway mpg'] = 23\n",
    "cars['Fuel Information.Highway mpg'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GS8zZlzUje0"
   },
   "source": [
    "But what if there's still a problem in another column? The standard way to deal with everything at once is using 1.5xIQR (Inter-Quartile-Range -- remember the placement of the boxplot whiskers?). As [this stackoverflow answer](https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles) says, 'Use this code and don't waste your time':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiz6VViEUje1"
   },
   "outputs": [],
   "source": [
    "# Start over with the outlier in again\n",
    "cars = pd.read_csv('https://corgis-edu.github.io/corgis/datasets/csv/cars/cars.csv')\n",
    "Q1 = cars.quantile(0.25)\n",
    "Q3 = cars.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "outliers = cars[ ((cars < (Q1 - 1.5 * IQR)) | (cars > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXWFpUOUUje1"
   },
   "outputs": [],
   "source": [
    "outliers.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WV7dX4gCUje2"
   },
   "outputs": [],
   "source": [
    "# Here's where we strip cars of outliers. Same as before except add a tilde ~\n",
    "cars     = cars[~((cars < (Q1 - 2 * IQR)) | (cars > (Q3 + 2 * IQR))).any(axis=1)]\n",
    "cars.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSqQxMY2Uje2"
   },
   "source": [
    "This kind of thing might remove more stuff than you want, like all the Bentleys and Lamborghinis etc that have outlier horsepower. You can try increasing 1.5 to maybe 2-3, or maybe just stick with the repair of isolated cells as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TDsFli7Uje2"
   },
   "source": [
    "# Setting column names\n",
    "\n",
    "It could be your data has no names on top of the columns, it could be you want to use your own column names which are easier to type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPcrmxjwUje3"
   },
   "outputs": [],
   "source": [
    "abalone=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data')\n",
    "abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DZi9FpNUje3"
   },
   "outputs": [],
   "source": [
    "colnames=['Sex', 'Length', 'Diameter', 'Height', 'Whole Weight', 'Shucked Weight', 'Viscera Weight', 'Shell Weight', 'Rings']\n",
    "abalone=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', names=colnames)\n",
    "abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrnRHFpzUje3"
   },
   "source": [
    "# Selecting DataFrame rows based on a condition\n",
    "\n",
    "Certainly everybody will have to do this fundamental pandas operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL0GQuvEUje4"
   },
   "outputs": [],
   "source": [
    "abalone['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-DAU0K8Uje4"
   },
   "outputs": [],
   "source": [
    "Mab = abalone[ abalone['Sex'] == 'M' ]\n",
    "Mab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dAddSyPUje4"
   },
   "outputs": [],
   "source": [
    "Fab = abalone[ abalone['Sex'] == 'F' ]\n",
    "Fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2p-Ai-IUje4"
   },
   "outputs": [],
   "source": [
    "Iab = abalone[ abalone['Sex'] == 'I' ]\n",
    "Iab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc1n5nUBpUrD"
   },
   "source": [
    "# Control the size of Seaborn catplots\n",
    "\n",
    "This is cramped, and there are a lot of errors about points not fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ey6caBSqacD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=abalone, x='Sex', y='Whole Weight', hue='Rings', kind='swarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh0xU_uAqtK9"
   },
   "source": [
    "sns.catplot() accepts height and aspect arguments. height=8 makes it taller, and aspect=2 makes it twice as wide as tall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=abalone, x='Sex', y='Whole Weight', hue='Rings', kind='swarm', height=8, aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're here, let's try some text and annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2pFGcZTpajj"
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=abalone, x='Sex', y='Whole Weight', hue='Rings', kind='swarm', height=8, aspect=2)\n",
    "a = plt.gca()\n",
    "# Note that all the x values are relative to category ticks being at 0,1,2\n",
    "a.text(0.5, 2.5, 'Howdy', color='purple')\n",
    "a.annotate('Doody', xy=(1, 2.65), xytext=(1.5,2.4),\n",
    "          color='r', arrowprops=dict(arrowstyle=\"->\", color='r'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODk62PZUje9"
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "Numpy can do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cYpISIFUje5"
   },
   "outputs": [],
   "source": [
    "elec = pd.read_csv('https://corgis-edu.github.io/corgis/datasets/csv/electricity/electricity.csv')\n",
    "elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These points look pretty linearly related\n",
    "plt.scatter(elec['Demand.Summer Peak'], elec['Demand.Winter Peak'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x range goes out past 30000, but the y range only goes up to about 25000. If we were to graph a line with slope of 1, it would not fit this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.arange(0, 32000, 1000) # this is (0, 1000, 2000, ...31000) not 32k, because python\n",
    "ax = plt.gca()\n",
    "ax.scatter(elec['Demand.Summer Peak'], elec['Demand.Winter Peak'])\n",
    "ax.plot(xrange, xrange, c='r', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, inter = np.polyfit(elec['Demand.Summer Peak'], elec['Demand.Winter Peak'], 1) # 1 is for linear\n",
    "slope, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope*xrange + inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that, rather than telling matplotlib to graph two pandas Series for you\n",
    "# you can tell pandas to tell matplotlib to graph two Series for you\n",
    "# Note ax= saves using an extra line for ax=plt.gca()\n",
    "ax=elec.plot('Demand.Summer Peak', 'Demand.Winter Peak', # x and y column names, without elec[]\n",
    "             kind='scatter')                             # kind of like seaborn\n",
    "ax.plot(xrange, slope*xrange + inter, c='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIa7pSpwUje5"
   },
   "source": [
    "# Grouping rows with common values\n",
    "\n",
    "The electricity dataset has multiple power companies per state. It can be useful to aggregate into a per-state DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNhQmWBfUje5"
   },
   "outputs": [],
   "source": [
    "# Sometimes the reasonable way to groupby() is .sum()\n",
    "elecStateSum = elec.groupby('Utility.State').sum()\n",
    "elecStateSum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exnULl7KUje6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sometimes (Demand.Summer.Peak ? ) max() may be more appropriate, or maybe sometimes mean()\n",
    "elecStateMax = elec.groupby('Utility.State').max()\n",
    "elecStateMax.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwlAqqZlUje6"
   },
   "source": [
    "# More complicated grouping\n",
    "\n",
    "There are multiple car makers from the same country, a new column can be put together to create a bulkier grouping than individual manufacturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LX4FdHX5Uje6"
   },
   "outputs": [],
   "source": [
    "cars['Identification.Make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmLxW1YxUje7"
   },
   "outputs": [],
   "source": [
    "# Set this first, EVERYBODY gets other, so after we set a bunch, we can see who we missed\n",
    "cars['Country'] = 'Other'\n",
    "cars['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a08jEgjUje7"
   },
   "outputs": [],
   "source": [
    "# I put this on multiple lines just so you can see the important parts more clearly\n",
    "cars.loc[ \n",
    "          cars['Identification.Make'].isin( ['Saab', 'Volvo'] ), \n",
    "          'Country' \n",
    "        ] = 'Sweden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEGgmQgjUje7"
   },
   "outputs": [],
   "source": [
    "cars.loc[ cars['Identification.Make'].isin( ['Audi', 'BMW', 'Mercedes-Benz', 'Porsche', 'Volkswagen' ] ), 'Country' ] = 'Germany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CtKSwZzUje8"
   },
   "outputs": [],
   "source": [
    "cars['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbRsfgTWUje8"
   },
   "outputs": [],
   "source": [
    "# Check what's left over\n",
    "leftovers = cars[ cars['Country'] == 'Other' ]\n",
    "leftovers['Identification.Make'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB2F0-gAUje8"
   },
   "source": [
    "# Making a function to graph lots of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqWNUfPFUje8"
   },
   "outputs": [],
   "source": [
    "bball = pd.read_csv('https://raw.githubusercontent.com/RubeRad/tcscs/master/Kenpom_cbb_dataALL.csv')\n",
    "bball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1RTFreepL1J"
   },
   "source": [
    "I expect this kind of code would get a bit repetitive, and cut&paste is never a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8QLdeKcUje8"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "axes=plt.gca()\n",
    "\n",
    "kentacky = bball[ bball['Team'] == 'Kentucky']\n",
    "kx = kentacky['Year']\n",
    "ky = kentacky['AdjO']\n",
    "axes.plot(kx, ky)\n",
    "\n",
    "alababama = bball[ bball['Team'] == 'Alabama']\n",
    "ax = alababama['Year']\n",
    "ay = alababama['AdjO']\n",
    "axes.plot(ax, ay)\n",
    "\n",
    "tennesaw  = bball[ bball['Team'] == 'Tennessee']\n",
    "tx = tennesaw['Year']\n",
    "ty = tennesaw['AdjO']\n",
    "axes.plot(tx, ty)\n",
    "\n",
    "axes.legend(['Kentucky', 'Alabama', 'Tennessee'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkKP2g0_Uje8"
   },
   "source": [
    "Better to make a function to do this kind of thing generically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTFugUj8Uje9"
   },
   "outputs": [],
   "source": [
    "def multi_plot(adf,        # a DataFrame\n",
    "               scol_name,  # the name of the column we are selecting rows from\n",
    "               scol_vals,  # the list of values we are selecting; one plot for each\n",
    "               xcol_name,  # the name of the column to use for X in each plot\n",
    "               ycol_name,  # the name of the column to use for Y in each plot\n",
    "               color=None, # if you let this stay None, matplotlib will choose colors\n",
    "               alpha=None, # if you let this stay None, alpha=opacity=1\n",
    "               scatter=False, # default plot (line)\n",
    "               axes=None   # if you don't pass axes in, axes for a new figure will be returned\n",
    "              ):\n",
    "\n",
    "    if axes == None:\n",
    "      plt.figure()\n",
    "      axes=plt.gca() \n",
    "\n",
    "    for val in scol_vals:\n",
    "        # Grab a DataFrame of just the values we want from the selection column\n",
    "        sub_df = adf[ adf[scol_name] == val ]\n",
    "        \n",
    "        # Grab the Series (columns) for X and Y\n",
    "        xs = sub_df[xcol_name]\n",
    "        ys = sub_df[ycol_name]\n",
    "        \n",
    "        # Plot these xs vs ys\n",
    "        if scatter:\n",
    "          axes.scatter(xs, ys, color=color, alpha=alpha)\n",
    "        else:\n",
    "          axes.plot(xs, ys, color=color, alpha=alpha)\n",
    "            \n",
    "    return axes # caller may want to graph more stuff, add titles, mess with range, etc etc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LK-HkuYJUje9"
   },
   "outputs": [],
   "source": [
    "#good_teams = ['Duke', 'Kentucky','Baylor','Virginia','Gonzaga']\n",
    "axes = multi_plot(bball, 'Team', bball['Team'].unique(), 'Year', 'AdjO', color='gray',   alpha=0.1)\n",
    "axes = multi_plot(bball, 'Team', ['Duke'],               'Year', 'AdjO', color='blue',   axes=axes)\n",
    "axes = multi_plot(bball, 'Team', ['Baylor'],             'Year', 'AdjO', color='yellow', axes=axes)\n",
    "axes = multi_plot(bball, 'Team', ['Virginia'],           'Year', 'AdjO', color='orange', axes=axes)\n",
    "#axes.legend( good_teams )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023 tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend clear this cell's output when it's done\n",
    "!pip install geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are how to load the world, U.S. states and U.S. counties geopandas datasets\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "states = gpd.read_file('https://raw.githubusercontent.com/RubeRad/camcom/master/us-albers.json')\n",
    "counties = gpd.read_file('https://raw.githubusercontent.com/RubeRad/tcscs/master/us_counties.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging pandas data with geopandas data\n",
    "### One data row per map row\n",
    "Very often, your interesting data will be in a pandas dataframe, but your map will be in a separate geopandas dataframe. This example shows how to merge them together in the simple case that your pieces of data are already just 1-for-1 with your map objects (map is states, data is one row per state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slurp a csv off the web\n",
    "ev2016 = pd.read_csv('https://raw.githubusercontent.com/RubeRad/camcom/master/2016ev.csv')\n",
    "ev2016.head() # note one state, one row, state name is in column 'State'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head(2) # also one state, one row, state name is in column 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has its own merge command, but to make sure your merged DataFrame retains its geopandas mapping goodness, you want to use geopandas own merge, like this:\n",
    "\n",
    "* `ev2016map = `: choose a variable name to hold the merged data\n",
    "* `states`: this is the map of the states\n",
    "* `.merge( ... )`: we want to merge another DataFrame together with this mapping one\n",
    "* `ev2016`: this is the other DataFrame we want to merge\n",
    "* -- but how do we know which rows should merge together? They need matching state names 'Alabama', 'Alaska', ...\n",
    "* `left_on='name'`: this is the column in `states` that has those state names\n",
    "* `right_on='State'`: this is the column in `ev2016` that has matching state names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map = states.merge(ev2016, left_on='name', right_on='State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the merged DataFrames\n",
    "`shape` helps to show if anything might have fallen out of the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do a `head()` on the merged dataframe (and maybe scroll to the right) you can check that it has columns from both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also `info()`, look especially at the \"Non-Null Count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the merged frame for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference between these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No difference, really! Both times they are making the map by plotting the Geometry column, and ignoring any data that is in any other columns\n",
    "\n",
    "Here, when you specify a column, geopandas can see that it's a categorical column with two values, and it chooses its own colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.plot(column='Winning Party')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to choose your own colors, you can make a new column filled with colors like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'red' and 'blue' is a little intense\n",
    "ev2016map['winning_party_color'] = ev2016map['Winning Party'].map({'Republicans':'pink', 'Democrats':'lightblue'})\n",
    "ev2016map.head()\n",
    "# scroll right to see new column 'party_color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.winning_party_color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2016map.plot(color=ev2016map.winning_party_color) #, edgecolor='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging with multiple data rows per map row\n",
    "\n",
    "This CORGIS dataset is the Washington Post database on deaths by police shootings (from 2015 to late 2021). \n",
    "\n",
    "Note there are multiple shootings per state -- because there are only 51 'states' (including DC) in the map, and over 6000 shootings in the WaPo data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo = pd.read_csv('https://corgis-edu.github.io/corgis/datasets/csv/police_shootings/police_shootings.csv')\n",
    "wapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive merging -- too many rows!\n",
    "Let's first try merging as before.\n",
    "* `wapo` has the state in column `Incident.Location.State`, with 2-letter values like `WA, OR, KS`, etc\n",
    "* to merge with the `states` mapping dataframe, we need to use column `iso_3166_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = states.merge(wapo, left_on='iso_3166_2', right_on='Incident.Location.State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK that has no errors, so it merged. What do we actually have? How big is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works but is slow!\n",
    "naive.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is also slow!\n",
    "# When it's done, what is this 'age' that is plotted for each state?\n",
    "naive.plot(column='Person.Age', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening there is that geopandas is going through all 6000+ rows of `naive`, and drawing each state. So each of the 50 states is overdrawn as many times as that state shows up in the dataframe. And the color that is shown for `'Person.Age'` is the age of whatever is the last person that gets (over)plotted for that state!\n",
    "\n",
    "Not useful!\n",
    "\n",
    "What we need is a data frame size 51, so it can line up individual ready-to-plot numerical values against the states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting *Counts*\n",
    "Let's say we want to just plot the *number* of shootings in each state (and without all that redundant overplotting). We need a 51-row dataframe with those counts in it, so when we merge, we have exactly the data we want. \n",
    "1. *First* work on the data to get it to 51 rows\n",
    "1. *Then* merge it with the map so it plots right (and quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note in the head(), Incident.Location.State is displayed lower, because it is the new 'index'\n",
    "# if you want that to go away, then add...                         THIS  \n",
    "wapo_counts = wapo.groupby('Incident.Location.State').count() # .reset_index()\n",
    "wapo_counts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE:*** All the columns have the same values! It's just the count of the number of rows that got combined by the `groupby()`. We can choose any of them when we end up plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_merge = states.merge(wapo_counts, left_on='iso_3166_2', right_on='Incident.Location.State')\n",
    "count_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_merge.plot(column='Person.Name', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is basically just saying \"there are more people in CA and TX to get shot by the police\". It would be better to make this per-capita, or per-million. Pandas can do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column that does arithmetic on other columns\n",
    "count_merge['count_per_million'] = count_merge['Person.Name'] / count_merge.census * 1000000\n",
    "count_merge.count_per_million.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_merge.plot(column='count_per_million', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting *Averages*\n",
    "In that last example we used `groupby().counts()`. There are other options, most notably `groupby().mean()` but also `.sum()`, `.max()`, `.min()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo_avg = wapo.groupby('Incident.Location.State').mean()\n",
    "# the warning is saying like \"I don't know how to take an average of a bunch of names, imma leave that out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapo_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of those remaining numerical columns that `groupby().mean()` knew how to compute a statewide average for, most of them are uninteresting (average month of the year is about 6, average day of the month is about 15, yeah years have 12 months and months have about 30 days)\n",
    "\n",
    "* What meaning might be present in per-state average Person.Age?\n",
    "* What meaning might be present in per-state average Incident.Date.Year?\n",
    "\n",
    "As before, we have to merge with the map before plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_merge = states.merge(wapo_avg, left_on='iso_3166_2', right_on='Incident.Location.State')\n",
    "avg_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_merge.plot(column='Person.Age', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this say? Why is NH (VT?) bright yellow? Why are CA/IL dark blue? Why are ND/SD/AK dark blue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_merge.plot(column='Incident.Date.Year', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this say? What does it mean that WY is so dark? What are the brightest states and what does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding coarse categories\n",
    "50 states is a lot, that would be too many colors to distinguish, or too many bars in a barplot to see what's going on. You can add a new column with a coarser categorization.\n",
    "\n",
    "This example shows how to add a categorical column to a dataframe and visualize it with geopandas or seaborn.\n",
    "I'm going to take a guess at labeling states as to whether they have a dominant party, or are a 'battleground' state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a new column, and fill it entirely with a nonsense value\n",
    "states['dominant'] = 'NOPE'     # creating a new column needs [' '] syntax\n",
    "states.dominant.value_counts()  # once the column exists, can switch to the simpler . syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step, choose a bunch of states and set their value in the new column\n",
    "# Note all these 2-letter abbreviations match what is found in column \n",
    "#            states.iso_3166_2\n",
    "Rstates = ['WY','KY','AL','MS','TX','ND','SD']  # not a complete list yet\n",
    "\n",
    "# now we select those rows\n",
    "whichrows = states.iso_3166_2.isin( Rstates )\n",
    "\n",
    "# the new column full of NOPE that we need to fill in is called 'dominant'\n",
    "whichcol = 'dominant'\n",
    "\n",
    "# now we can use the pandas loc[] command to set the color value for those states\n",
    "states.loc[whichrows, whichcol] = 'Republican'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does it look now?\n",
    "states.dominant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the same in two lines, for some blue states\n",
    "Dstates = ['CA', 'OR', 'WA', 'NY', 'MA', 'DC']\n",
    "states.loc[ states.iso_3166_2.isin(Dstates),  'dominant' ] = 'Democrat'\n",
    "# could actually do it in one line, putting that whole [] list inside the isin()\n",
    "# but that would be a very long line, hard to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does it look now?\n",
    "states.dominant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bstates = ['PA','OH','FL','GA','WI','MN','MI']\n",
    "states.loc[ states.iso_3166_2.isin(Bstates), 'dominant'] = 'Battleground'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does it look now?\n",
    "states.dominant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's missing? make a slice to see what states still need assignments\n",
    "nopestates = states[ states.dominant == 'NOPE' ]\n",
    "nopestates.head()\n",
    "#nopestates.iso_3166_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when it's all done it will look more like this\n",
    "Rstates = ['WY','KY','AL','MS','TX','ND','SD','AR','LA','MT','OK','TN','WV','ID','KS','SC','UT','IA','NE','NH'] \n",
    "Dstates = ['CA', 'OR', 'WA', 'NY', 'MA', 'DC','CT','IL','VA','DE','MD','NJ','VT','ME','RI']\n",
    "Bstates = ['PA','OH','FL','GA','WI','MN','MI','AZ','CO','IN','NM','NC','MO','NV','AK','HI']\n",
    "states.loc[ states.iso_3166_2.isin(Rstates),  'dominant' ] = 'Republican'\n",
    "states.loc[ states.iso_3166_2.isin(Dstates),  'dominant' ] = 'Democrat'\n",
    "states.loc[ states.iso_3166_2.isin(Bstates),  'dominant' ] = 'Battleground'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopestates = states[ states.dominant == 'NOPE' ]\n",
    "nopestates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the categorization: Way 1\n",
    "Make a separate slice per category and use a separate plot to put them all on the same axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRep = states[ states.dominant=='Republican']\n",
    "dfDem = states[ states.dominant=='Democrat']\n",
    "dfBtl = states[ states.dominant=='Battleground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "axes=plt.gca()\n",
    "\n",
    "dfRep.plot(ax=axes, color='r')\n",
    "dfDem.plot(ax=axes, color='b')\n",
    "dfBtl.plot(ax=axes, color='purple')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the categorization: Way 2\n",
    "Make a new column full of color codes/names and tell geopandas to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states['dominant_party_color'] = 'red' # everybody's red, EXCEPT...\n",
    "# use the .loc command to change colors for the other categories\n",
    "#           < first part is which rows   >\n",
    "#                                            < second part is col >\n",
    "#                                                                      < last is new value>\n",
    "states.loc[ states.dominant=='Democrat',     'dominant_party_color' ] = 'blue'\n",
    "states.loc[ states.dominant=='Battleground', 'dominant_party_color' ] = 'purple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head()\n",
    "# scroll right to check dominant_party_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.dominant_party_color.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot(color = states.dominant_party_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things you can do with categorization: Use seaborn for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-merge with washington post counts, now that states has the categorization columns\n",
    "count_merge = states.merge(wapo_counts, left_on='iso_3166_2', right_on='Incident.Location.State')\n",
    "count_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=count_merge, x='dominant', y='Person.Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things you can do with categorization: Use geopandas for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_merge = states.merge(wapo_avg, left_on='iso_3166_2', right_on='Incident.Location.State')\n",
    "avg_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRep = avg_merge[ avg_merge.dominant=='Republican']\n",
    "dfDem = avg_merge[ avg_merge.dominant=='Democrat']\n",
    "dfBtl = avg_merge[ avg_merge.dominant=='Battleground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "axes=plt.gca()\n",
    "\n",
    "dfRep.plot(ax=axes, column='Person.Age', cmap='Reds',    legend=True)\n",
    "dfDem.plot(ax=axes, column='Person.Age', cmap='Blues',   legend=True)\n",
    "dfBtl.plot(ax=axes, column='Person.Age', cmap='Purples', legend=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "InfographicTips.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
