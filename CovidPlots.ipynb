{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubeRad/tcscs/blob/master/CovidPlots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77-aZCKD1c4Z"
      },
      "source": [
        "# Introduction to Python, Jupyter, Pandas, and Matplotlib\n",
        "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
        "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
        "  - For Markdown cells, 'execute' means render the formatting. ([Here's a markdown cheatsheet](https://sqlbak.com/blog/wp-content/uploads/2020/04/Jupyter-Notebook-Markdown-Cheatsheet.pdf))\n",
        "  - For Code cells, 'execute' means run the python.\n",
        "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
        "1. Any cell can be edited (double-click into it) and re-executed (SHIFT-ENTER again).\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZid-1MF1c4a"
      },
      "source": [
        "The first code in any Python script/Jupyter notebook, needs to import any libraries that will be used. The `as` directives allow specification of nicknames that are more convenient to type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YLF-sx31c4b"
      },
      "outputs": [],
      "source": [
        "from datetime import date        # Because we're going to be plotting time series\n",
        "from dateutil import parser      # To make it easier to parse YYYY-MM-DD strings\n",
        "import matplotlib.pyplot as plt  # This is for creating graphs\n",
        "import pandas            as pd   # This greatly simplifies handling of tabular (csv) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_En7DUu1c4c"
      },
      "source": [
        "The `pandas` function `read_csv()` can read .csv files on your computer, but it's so smart it can even slurp in a .csv directly from online. This reads in the csv data linked to on this page: https://ourworldindata.org/coronavirus-source-data). \n",
        "\n",
        "It takes a few seconds to download, watch for the `*` to change to a number. \n",
        "\n",
        "**The two most important terms in the grammar of pandas are `DataFrame` and `Series`/column**. A `DataFrame` is equivalent to  one tab of a spreadsheet (or one worksheet of a workbook). Each column of the `DataFrame` is one `Series`. The data object returned by `read_csv()` is held in a variable named `df` which stands for `DataFrame`.\n",
        "\n",
        "Note: Python is happy with specifying text constants (strings) with either single or double quotes, but single are preferred because they read cleaner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-3fNc6a1c4c"
      },
      "outputs": [],
      "source": [
        "url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n",
        "dfall  = pd.read_csv(url)  # this takes a few seconds because it has to download the file\n",
        "#dfall  = pd.read_csv(url, parse_dates=['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFZxJDm81c4c"
      },
      "source": [
        "One thing you can do it Jupyter Notebooks that you can't do in regular Python scripts (programs), is to just mention something at the end of a code cell, which is a request for the notebook to display it. If it's too big to be printed completely, it will be automatically summarized. For starters, you can try to get a glimpse of the whole `DataFrame` object itself. The `NaN` ('not a number') are empty cells in the csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKb_jonk1c4c"
      },
      "outputs": [],
      "source": [
        "dfall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGYGj0wF1c4d"
      },
      "source": [
        "Here are a few more ways to describe/understand the data, execute each cell and take a minute to read and understand what information is provided:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKnzMtvJ1c4d"
      },
      "outputs": [],
      "source": [
        "dfall.shape     # note shape is a 'data member', a variable that belongs to every data frame. (Rows, Columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZoSDrt91c4d"
      },
      "outputs": [],
      "source": [
        "dfall.columns   # pandas assumes the first row of the csv are column headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt0bc2ky1c4d"
      },
      "outputs": [],
      "source": [
        "# info is a 'class function', so it needs (); sometimes input parameters go in there.\n",
        "dfall.info() # Data size, column headers, counts, and types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_uL2Zmt1c4e"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Note that the type listed for column `3 date` up there, is just `object`. For proper handling, we want pandas to see that as type `datetime`. Go back up to the `read_csv(url)` line and uncomment the 2nd option to tell pandas to re-read the data that way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYfKZP7N1c4e"
      },
      "outputs": [],
      "source": [
        "dfall.describe() # some common statistics on each column, note you can scroll to the right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Egx3cNBb1c4e"
      },
      "outputs": [],
      "source": [
        "dfall.head() # first few rows of data (default 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zklF9cV1c4e"
      },
      "outputs": [],
      "source": [
        "dfall.tail(8) # last few rows of data (we specify 8 here, just to show how)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAz5td2K1c4e"
      },
      "source": [
        "# Choosing individual columns by name\n",
        "\n",
        "Any individual `Series` (column) can be fetched out of the data frame using square brackets, and some of the same functions apply, as well as a few others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z7NDlB71c4f"
      },
      "outputs": [],
      "source": [
        "dfall['iso_code']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCHIP5431c4f"
      },
      "outputs": [],
      "source": [
        "dfall['iso_code'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5-dK1J71c4f"
      },
      "outputs": [],
      "source": [
        "dfall['iso_code'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsFeCeu1c4f"
      },
      "outputs": [],
      "source": [
        "dfall['iso_code'].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcV1VECz1c4f"
      },
      "outputs": [],
      "source": [
        "dfall['iso_code'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9pzVd4X1c4f"
      },
      "source": [
        "## Exercise\n",
        "* Go back into those cells above, and edit to investigate some other Series, like 'location', 'date', 'new_cases'\n",
        "* Change the first line to `series = df['iso_code']`, and for the rest of the lines use the variable `series` instead of repeating `df['iso_code']` all the time. \n",
        "* Then edit `'iso_code'` in the first line to other column names, and rerun the following cells to see different results.\n",
        "* 'value_counts()' has different top numbers for `iso_code` vs `location` vs `date`. What does that mean?\n",
        "* Finally, test the shortcut syntax for accessing columns, like `df.iso_code`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FpPh4o1c4g"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtMQMz311c4g"
      },
      "source": [
        "# Slicing a DataFrame down to a subset of columns\n",
        "A smaller `DataFrame` can be created from any group of `Series` (columns) that you choose. As always in Python, take careful note of the syntax, with `[]` inside `[]`, and quotes and commas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zNAYQw-t1c4g"
      },
      "outputs": [],
      "source": [
        "# dfall is all the data, let's call this smaller DataFrame df\n",
        "df = dfall[  ['iso_code', 'location', 'date', 'new_cases', 'new_deaths', 'total_cases', 'population']  ]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsQuJMq91c4g"
      },
      "source": [
        "# Slicing DataFrame rows with a condition\n",
        "A `DataFrame` can be 'sliced' (filtered) based on conditions applied to the data. These actions can be read something like \"The new variable USA is a `DataFrame` made from df by selecting all the rows for which the 'iso_code' is equal to the text constant 'USA'\"\n",
        "\n",
        "***Critically important Python NOTE:*** One = means the action **assignment**, whatever is on the right, put it into the left. It is the same as Snap's `Set <variable> to <value>` from the  yellow Variables tab.  Two == means the **question** *are these two things the same* (or in this context, *where* are these two the same?), and is equivalent to the Predicate = in Snap!, from the green Operators tab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r03FO_zJ1c4g"
      },
      "outputs": [],
      "source": [
        "AFGrows = df['iso_code'] == 'AFG' # this is a Series of 61245 False/True; it's True in all the rows with iso_code=='USA'\n",
        "AFGrows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLGIZEpQ1c4h"
      },
      "source": [
        "Once we have a list of True/False flags for all the rows, we can use that to filter the DataFrame to a smaller DataFrame with just the rows flagged True. Note that the resulting DataFrame is all `iso_code==AFG`, and fewer rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdOqswx41c4h"
      },
      "outputs": [],
      "source": [
        "AFG = df[ AFGrows ]\n",
        "AFG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdUV-Cpj1c4h"
      },
      "source": [
        "Note we can do the above steps in one line per country, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18kP08e_1c4h"
      },
      "outputs": [],
      "source": [
        "# You can change to your own list of countries\n",
        "USA = df[ df['iso_code'] == 'USA' ] # Set variable USA to the DataFrame of the rows of df with iso_code==USA\n",
        "ITA = df[ df['iso_code'] == 'ITA' ]\n",
        "SWE = df[ df.iso_code == 'SWE' ]    # and we can even use the shortcut notation!\n",
        "KOR = df[ df.iso_code == 'KOR' ]\n",
        "\n",
        "# Make a list of the nice names of countries, so we don't have\n",
        "# to type it over and over for every plot.legend()\n",
        "countries = ['United States', 'Italy', 'Sweden', 'South Korea']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1ZNRSgj1c4h"
      },
      "source": [
        "## Exercise\n",
        "Use the following cell to try various looks at these sliced DataFrames, like USA.info() or SWE.tail(), etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3R2nF1x1c4h"
      },
      "outputs": [],
      "source": [
        "\n",
        "USA.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI1tCB6F1c4h"
      },
      "source": [
        "# Plotting Pandas Series' with MATPLOTLIB\n",
        "Now that we have a handle on manipulating csv data with pandas, we turn to the main point, which is to be able to visualize the data graphically. Here's a naive plot to start with. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf1gDHQx1c4i"
      },
      "outputs": [],
      "source": [
        "USAx = USA['date']      # grab the Series 'date'      out of the USA DataFrame into a variable called USAx\n",
        "USAy = USA['new_cases'] # grab the Series 'new_cases' out of the USA DataFrame into a variable called USAy\n",
        "plt.figure(figsize=(16,8))\n",
        "ax = plt.gca()\n",
        "ax.plot(USAx, USAy)\n",
        "\n",
        "# Also plot series for the other countries, can be done in one line each\n",
        "ax.plot(ITA.date, ITA.new_cases) \n",
        "\n",
        "#ax.legend(countries)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8NffThP1c4i"
      },
      "source": [
        "First off, those curves are obviously incomparable because of quite different country populations. We can convert to per-million by applying arithmetic to the whole series (requires knowledge of the country population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr9JgmwR1c4i"
      },
      "outputs": [],
      "source": [
        "USA.new_cases\n",
        "# USA.new_cases / USA.population             # row-by-row divide to get per-capita\n",
        "# USA.new_cases / USA.population * 1000000   # per capita is too small, so scale up to per million"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nndC4C1H1c4i"
      },
      "outputs": [],
      "source": [
        "# Same as the above plot, except scaling per million (USA~331M, etc)\n",
        "USAperM = USA.new_cases / USA.population\n",
        "plt.figure(figsize=(16,8))\n",
        "ax = plt.gca()\n",
        "ax.plot(USAx, USAperM)\n",
        "#add the other countries to the plot\n",
        "#ax.legend(countries)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM8U2zbL1c4i"
      },
      "source": [
        "Next let's smooth out those weekly cycles with a 7-day average"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.parse('2020-12-09')"
      ],
      "metadata": {
        "id": "0GQuHVMo-Rz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0i2MvMk1c4i"
      },
      "outputs": [],
      "source": [
        "USAperMrollWeek = USAperM.rolling(window=7) # this tracks statistics on a rolling window of 7 rows (days)\n",
        "USAperMweekAvg  = USAperMrollWeek.mean()    # this grabs the mean() (average), as opposed to min/max/med, etc.\n",
        "plt.figure(figsize=(16,8))\n",
        "ax=plt.gca()\n",
        "ax.plot(USAx, USAperMweekAvg)\n",
        "# add the other countries\n",
        "#ax.legend(countries)\n",
        "\n",
        "\n",
        "# Try these out...\n",
        "plt.axvline(parser.parse('2020-12-09'), c='r', ls=':')\n",
        "plt.text(x=parser.parse('2020-12-15'), y=100, s=\"Last year's class\", c='r')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jYYfpUG1c4j"
      },
      "source": [
        "# Exercise\n",
        "Modify this notebook to make the following changes:\n",
        "\n",
        "1. Remove S. Korea (they did so well, they can barely be seen on the graph!)\n",
        "1. Add **TWO** countries of your choosing that make this graph more interesting (note you'll have to google the population of those two new countries)\n",
        "1. Change the graph to be **deaths per million** (so far all the graphs have been  **cases per million**) \n",
        "\n",
        "Here is a table of abbreviations that you might find helpful (but you don't have to pick from these)\n",
        "\n",
        "|iso_code  | location |iso_code  | location |\n",
        "|:---------|:---------|:---------|:---------|\n",
        "|AUS       | Australia|IRN       | Iran     |\n",
        "|BRA       | Brazil   |ISR       | Israel   |\n",
        "|CAN       | Canada   |MEX       | Mexico   |\n",
        "|ESP       | Spain    |NZL       | New Zealand |\n",
        "|FRA       | France   |RUS       | Russia   |\n",
        "|GBR       | United Kingdom |ZAF | South Africa |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtwgLb_g1c4j"
      },
      "source": [
        "# World Aggregation\n",
        "We can add all the countries together. `groupby(['date']).sum()` says we want a new dataframe, with a row for every unique date, and all the other columns are added up per date.\n",
        "\n",
        "(For some situations, it might make more sense to `groupby(['date']).mean()`)\n",
        "\n",
        "Note how `world.head()` prints the date in bold; that's because it is now the 'index', not a regular column. Repeat the cell with `.reset_index()` active, and you will see that date is set to a regular column again (and the index is just a running counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Q3bRjLjB1c4j"
      },
      "outputs": [],
      "source": [
        "world = df.groupby(['date']).sum()    #.reset_index()\n",
        "world.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha_u-hMw1c4k"
      },
      "source": [
        "All the same kinds of plotting that happened above can be done with this world dataframe. If `.reset_index()` is used, then the x for the plots can be `world['date']` as before; if `.reset_index()` is *not* used, then the x for plotting must be `world.index`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bijgaAbD1c4k"
      },
      "outputs": [],
      "source": [
        "dateX   = world.index         # or world['date'] if .reset_index() is used\n",
        "casesY  = world['new_cases']  # rolling average gets applied on these two lines\n",
        "deathsY = world['new_deaths']\n",
        "\n",
        "plt.figure()\n",
        "ax = plt.gca()\n",
        "ax.plot(dateX, casesY)\n",
        "\n",
        "# This is how you have a 2nd y axis on the right; two Axes share the same (twin) X axis\n",
        "ax2 = ax.twinx()  \n",
        "ax2.plot(dateX, deathsY)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI7Ao7kL1c4k"
      },
      "source": [
        "# Exercise\n",
        "Improve the graph above in the following ways:\n",
        "1. Initialize the figure to have a larger figsize with an attractive aspect ratio.\n",
        "1. Use a 7-day rolling average instead of the raw numbers\n",
        "1. Use set_ylabel() to describe the left and right axes, and use set_title() to title the whole chart\n",
        "1. Use different colors for the cases/deaths graphs\n",
        "1. Use plt.legend()\n",
        "1. Use the plt.axvline() example above to annotate a few significant dates, such as the start of vaccination, the discovery of the Delta/Omicron variants, etc.\n",
        "1. Use plt.text() or plt.annotate() (example in the MatplotlibIntro notebook) to annotate 'First Wave', 'Second Wave', etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnKaRSCK1c4l"
      },
      "source": [
        "---\n",
        "# Optional extra: Shifted Dates\n",
        "\n",
        "Most complicated, we can see that these curves would be more comparable if they were date-shifted, to reflect the different times when the pandemic hit different countries. A common technique is to line them all up based on when they had a certain common minimum number of cases, say 10. We will filter on a condition again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImVxqJLQ1c4l"
      },
      "outputs": [],
      "source": [
        "# I could just type 100 in every line below, but this way if I want to experiment with a different value\n",
        "# I can edit just 1 line, instead of having to edit a line for every country (especially as countries are added)\n",
        "min_cases = 100\n",
        "USAsh = USA[ USA['total_cases'] >= min_cases ]  # 'sh' for shift\n",
        "ITAsh = ITA[ ITA['total_cases'] >= min_cases ]\n",
        "SWEsh = SWE[ SWE['total_cases'] >= min_cases ]\n",
        "KORsh = KOR[ KOR['total_cases'] >= min_cases ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaAqR3gW1c4m"
      },
      "outputs": [],
      "source": [
        "USAsh['date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0L6v3Ey1c4m"
      },
      "outputs": [],
      "source": [
        "USAsh['date'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO2T4RSI1c4m"
      },
      "outputs": [],
      "source": [
        "ITAsh['date'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKwtkZnL1c4m"
      },
      "outputs": [],
      "source": [
        "USAsh['date'].min() - ITAsh['date'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrHEBICE1c4m"
      },
      "source": [
        "Now we can see above that Italy reached 100 cases on Feb 24, 8 days before the US on Mar 3. (And that date objects can be subtracted!)\n",
        "\n",
        "Here are all the dates where these countries reached 100 cases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXLU8POh1c4m"
      },
      "outputs": [],
      "source": [
        "USAt0 = USAsh['date'].min()\n",
        "ITAt0 = ITAsh['date'].min()\n",
        "SWEt0 = SWEsh['date'].min()\n",
        "KORt0 = KORsh['date'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XuEqPz_1c4n"
      },
      "source": [
        "Just like we were able to simply multiply and divide the entire 'new_cases' Series by constant numbers, we can subtract the start date from the date Series, yielding number of days since 100 cases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5djyfH3a1c4n"
      },
      "outputs": [],
      "source": [
        "USAsh['date'] - USAt0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "4kKf3V4y1c4n"
      },
      "outputs": [],
      "source": [
        "USAshX = USAsh['date'] - USAt0\n",
        "USAshY = USAsh['new_cases'].rolling(window=7).mean()/331\n",
        "plt.figure(figsize=(16,8))\n",
        "ax = plt.gca()\n",
        "ax.plot(USAshX, USAshY)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kh-q5kl1c4n"
      },
      "source": [
        "Note that plot goes from 0 to 2.5e16. Even though the description of `USAsh['date'] - USAt0` above says 'days', matplotlib is interpreting it as milliseconds. We can fix this by forcing conversion to days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e91n-dq91c4n"
      },
      "outputs": [],
      "source": [
        "USAshX = (USAsh['date'] - USAt0).astype('timedelta64[D]')   # 'D' is for Days\n",
        "USAshX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "0LE82VBv1c4o"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "ax = plt.gca()\n",
        "ax.plot(USAshX, USAshY)\n",
        "ax.plot((ITAsh['date']-ITAt0).astype('timedelta64[D]'), ITAsh['new_cases'].rolling(window=7).mean()/60)  \n",
        "ax.plot((SWEsh['date']-SWEt0).astype('timedelta64[D]'), SWEsh['new_cases'].rolling(window=7).mean()/10) \n",
        "ax.plot((KORsh['date']-KORt0).astype('timedelta64[D]'), KORsh['new_cases'].rolling(window=7).mean()/51)\n",
        "ax.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
        "ax.set_xlim( (0, 300) )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i12dvJ8Z1c4o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}